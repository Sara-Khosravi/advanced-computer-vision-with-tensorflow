{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed911aaf",
   "metadata": {
    "papermill": {
     "duration": 0.007778,
     "end_time": "2025-07-21T17:38:44.317505",
     "exception": false,
     "start_time": "2025-07-21T17:38:44.309727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AEI Telecom Failure Simulator Module: Zero-to-Production Roadmap\n",
    "\n",
    "This roadmap outlines the systematic development and validation phases for the `aei.telecom.failure.failure_simulator` Python module. This module is responsible for orchestrating and executing simulations of telecom network failures, leveraging validated configurations provided by the `AEIFailureConfigManager`.\n",
    "\n",
    "## Phase -1: Module Scaffolding\n",
    "* [ ] Module Creation: Established as `failure_simulator.py` within the `aei.telecom.failure` package structure.\n",
    "    ```\n",
    "    aei/\n",
    "    └── telecom/\n",
    "        └── failure/\n",
    "            ├── __init__.py\n",
    "            ├── config.py\n",
    "            └── failure_simulator.py  # This module\n",
    "    ```\n",
    "* [ ] External Dependencies: Identify and include necessary external libraries (e.g., `numpy` for numerical operations, `pandas` for data handling).\n",
    "    ```python\n",
    "    # Example dependencies\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ```\n",
    "* [ ] Internal Dependencies: Import and utilize the `AEIFailureConfigManager` (or its `FailureConfig` output) for simulation parameters.\n",
    "    ```python\n",
    "    from aei.telecom.failure.config import FailureConfig, AEIFailureConfigManager\n",
    "    ```\n",
    "* [ ] Dedicated Logger: Configure a specific logger instance for precise log management within the simulation process.\n",
    "    ```python\n",
    "    import logging\n",
    "    logger = logging.getLogger(\"aei.telecom.failure.failure_simulator\")\n",
    "    logger.setLevel(logging.INFO) # Default to INFO for simulation progress\n",
    "    ```\n",
    "* **Tools**: Python Standard Library, `numpy`, `pandas` (or other data science libraries)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 0: Design & Architecture\n",
    "* [ ] Core Class Defined:\n",
    "    * `AEIFailureSimulator`: The central class for setting up and running network failure simulations.\n",
    "* [ ] Simulation Method Signature: Define clear inputs (validated configuration, network topology/state data, simulation duration) and outputs (simulation results, metrics).\n",
    "    ```python\n",
    "    # Example method signature\n",
    "    class AEIFailureSimulator:\n",
    "        def __init__(self, config: FailureConfig):\n",
    "            self.config = config\n",
    "            # ... initialize simulation environment ...\n",
    "\n",
    "        def simulate(\n",
    "            self,\n",
    "            network_topology: Dict[str, Any],\n",
    "            initial_user_data: pd.DataFrame,\n",
    "            duration_steps: int\n",
    "        ) -> Dict[str, Any]:\n",
    "            # ... simulation logic ...\n",
    "            pass\n",
    "    ```\n",
    "* [ ] Integration with Configuration: Ensure seamless consumption of `FailureConfig` object from `AEIFailureConfigManager`.\n",
    "* [ ] Output Data Structure: Design the format of simulation results (e.g., failed cells over time, dropped call counts, performance degradation metrics).\n",
    "* [ ] Modularity for Failure Models: Consider abstracting different failure types (e.g., power outage, backhaul failure) into separate, interchangeable models if complexity warrants.\n",
    "* **Tools**: Conceptual Design, Data Schemas\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1: Core Implementation\n",
    "* [ ] Initialization Logic: Set up the simulation environment based on the provided `FailureConfig`. This might involve pre-calculating probabilities or setting up internal state.\n",
    "* [ ] Main Simulation Loop: Implement the iterative process of the simulation, step by step, applying failure conditions and observing network behavior.\n",
    "* [ ] Failure Injection Logic: Integrate the `FailureType` probabilities and thresholds from `config` to determine when and how failures occur.\n",
    "    ```python\n",
    "    # Example: Inside simulate method\n",
    "    for step in range(duration_steps):\n",
    "        # Apply random failures based on self.config.failure_probabilities\n",
    "        if np.random.rand() < self.config.power_outage_probability:\n",
    "            self._inject_power_outage()\n",
    "        # ... other failure types ...\n",
    "\n",
    "        # Recalculate network state and metrics\n",
    "        # ...\n",
    "    ```\n",
    "* [ ] Metric Calculation: Implement the logic to derive key performance indicators (KPIs) and impact metrics based on the simulated network state.\n",
    "* [ ] Error Handling: Implement error handling for scenarios specific to the simulator (e.g., invalid network input, unhandled simulation states).\n",
    "* **Tools**: `numpy`, `pandas` (for data manipulation within simulation)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1.5: Code Quality\n",
    "* [ ] Type Hinting: Apply comprehensive type hints to all function parameters, return values, and class attributes for clarity and maintainability.\n",
    "* [ ] Readability & Style: Adhere to PEP 8 guidelines, using clear variable names and concise function definitions.\n",
    "* [ ] Logging Implementation: Integrate `logger.info` for major simulation steps, `logger.debug` for detailed internal calculations, and `logger.warning`/`logger.error` for unusual or problematic simulation events.\n",
    "    ```python\n",
    "    # Example logging within simulation\n",
    "    logger.info(f\"Starting simulation for {duration_steps} steps.\")\n",
    "    logger.debug(f\"Step {step}: Applied {num_failures} new failures.\")\n",
    "    ```\n",
    "* **Tools**: Python Type Hinting\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 2: Testing (External Unit & Integration Test Coverage)\n",
    "* [ ] Unit Tests for Simulation Components: Test individual failure injection models, metric calculation functions, or state update logic in isolation.\n",
    "    ```python\n",
    "    # Example unit test for a specific failure model\n",
    "    def test_power_outage_injection():\n",
    "        simulator = AEIFailureSimulator(mock_config_with_power_outage)\n",
    "        initial_state = {\"cell_A\": \"active\"}\n",
    "        # ... apply power outage ...\n",
    "        assert \"cell_A\" == \"failed\"\n",
    "    ```\n",
    "* [ ] Integration Tests for Full Simulation Runs: Run the `simulate` method with various `FailureConfig` objects and simplified network data, asserting on expected outcomes (e.g., number of dropped calls, specific cells failing).\n",
    "    ```python\n",
    "    # Example integration test\n",
    "    def test_end_to_end_simulation():\n",
    "        config_manager = AEIFailureConfigManager({\"probabilities\": {\"dropped_call\": 0.5}})\n",
    "        config = config_manager.create_failure_config()\n",
    "        simulator = AEIFailureSimulator(config)\n",
    "        results = simulator.simulate(simple_network, simple_users, 100)\n",
    "        assert results[\"total_dropped_calls\"] > 0\n",
    "    ```\n",
    "* [ ] Regression Tests: Create a suite of tests to ensure that changes to the simulation logic do not inadvertently alter previously validated behavior.\n",
    "* [ ] Performance Tests (Basic): Measure execution time for simple simulation runs to establish a baseline.\n",
    "* **Tools**: `unittest` or `pytest` (external)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 3: Documentation\n",
    "* [ ] Class and Method Docstrings: Provide comprehensive docstrings for the `AEIFailureSimulator` class and its `simulate` method, explaining purpose, parameters, and return values.\n",
    "* [ ] Usage Examples: Develop clear, runnable examples demonstrating how to initialize the simulator, provide inputs, run a simulation, and interpret outputs.\n",
    "* [ ] Input Data Specification: Document the required format and structure of `network_topology` and `initial_user_data`.\n",
    "* [ ] Output Data Dictionary: Provide a clear explanation of all keys and values in the dictionary returned by the `simulate` method.\n",
    "* **Tools**: Python Docstrings, Markdown (for overall project documentation)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 4: Packaging (Integration into Larger Project)\n",
    "* [ ] Module Inclusion: This `failure_simulator.py` module will be included as part of the broader `aei.telecom.failure` Python package distribution.\n",
    "* [ ] `pyproject.toml` / `setup.py` Entry: Its inclusion will be managed by the parent project's packaging configuration.\n",
    "* **Tools**: `setuptools` / `poetry` (of the parent project)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 5: CI/CD Automation (Part of Parent Project's Pipeline)\n",
    "* [ ] Automated Test Execution: Unit and integration tests for this module will be executed automatically as part of the parent project's continuous integration pipeline.\n",
    "* [ ] Simulation Regression Runs: Consider including automated \"mini-simulations\" in CI/CD to catch regressions in core simulation behavior or performance.\n",
    "* [ ] Code Quality Gates: Linting and type checking for this module's code will be enforced during CI.\n",
    "* **Tools**: GitHub Actions, GitLab CI, Jenkins (of the parent project)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 6: Production Readiness\n",
    "* [ ] Scalability & Performance: Optimize the simulator for performance and memory usage, especially for large-scale network simulations or long durations. Consider parallelization if applicable.\n",
    "* [ ] Reproducibility: Ensure simulation results are reproducible given the same inputs and random seeds.\n",
    "* [ ] Resource Management: Implement graceful handling of system resources (CPU, memory) to prevent crashes during long or intense simulations.\n",
    "* [ ] Error Reporting & Monitoring: Integrate the simulator's logs and exceptions with a centralized monitoring system to track simulation health and identify issues.\n",
    "* [ ] Robust Input Handling: Implement robust validation for `network_topology` and `initial_user_data` inputs beyond just type checking.\n",
    "* **Tools**: Profilers, `pytest-benchmark`, Application Monitoring (e.g., Sentry, Prometheus), Logging Aggregation (e.g., ELK Stack)\n",
    "\n",
    "---\n",
    "\n",
    "### Final Checklist (for `aei.telecom.failure.failure_simulator`)\n",
    "\n",
    "1.  [ ] **Core Simulation Logic Implemented**: Applies failure models based on configuration.\n",
    "2.  [ ] **Integration with `FailureConfig`**: Seamlessly consumes validated configuration.\n",
    "3.  [ ] **Clear Input/Output Contracts**: Well-defined data structures for simulation inputs and results.\n",
    "4.  [ ] **Comprehensive Internal Logging**: Provides visibility into simulation progress and events.\n",
    "5.  [ ] **Robust Error Handling**: Catches and reports simulation-specific issues.\n",
    "6.  [ ] **Thorough Unit & Integration Tests**: Validates simulation components and overall behavior.\n",
    "7.  [ ] **Performance Benchmarked**: Establishes and tracks simulation speed.\n",
    "8.  [ ] **Reproducible Results**: Ensures consistent outputs for identical inputs.\n",
    "9.  [ ] **Integrated into Parent Package**: (Future, deployment phase)\n",
    "10. [ ] **Covered by Parent Project's CI/CD**: (Future, CI/CD phase)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89593e54",
   "metadata": {
    "papermill": {
     "duration": 0.005851,
     "end_time": "2025-07-21T17:38:44.330059",
     "exception": false,
     "start_time": "2025-07-21T17:38:44.324208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```bash\n",
    "/kaggle/working/\n",
    "├── aei/\n",
    "│   ├── telecom/\n",
    "│   │   ├── failure/\n",
    "│   │   │   ├── __init__.py\n",
    "│   │   │   ├── config.py             # Assuming this file exists from previous steps\n",
    "│   │   │   └── failure_simulator.py  # The code you provided\n",
    "├── tests/\n",
    "│   ├── __init__.py\n",
    "│   └── test_failure_simulator.py\n",
    "└── data_quality_report.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a27d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T17:38:44.344751Z",
     "iopub.status.busy": "2025-07-21T17:38:44.344438Z",
     "iopub.status.idle": "2025-07-21T17:38:46.506930Z",
     "shell.execute_reply": "2025-07-21T17:38:46.505809Z"
    },
    "papermill": {
     "duration": 2.172422,
     "end_time": "2025-07-21T17:38:46.508699",
     "exception": false,
     "start_time": "2025-07-21T17:38:44.336277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. SCRIPT SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "# Configure logging for clear, informative output\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define constants for module name and paths for clarity and easy modification\n",
    "MODULE_NAME = \"aei.telecom.failure.config\"\n",
    "BASE_DIR = \"/kaggle/working/aei/telecom/failure\"\n",
    "CONFIG_FILE_PATH = os.path.join(BASE_DIR, \"config.py\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THE MODULE'S SOURCE CODE\n",
    "# ==============================================================================\n",
    "\n",
    "# The source code for the config.py module with all fixes applied.\n",
    "failure_config_code = textwrap.dedent('''\n",
    "# -------------------------------\n",
    "# ⚠️ AEI Failure Configuration Manager\n",
    "# -------------------------------\n",
    "# aei/telecom/failure/config.py\n",
    "# Author: AID Edge Inc. Network Reliability Team\n",
    "# Date: 2025-07-16 (Cleaned logger configuration for assertLogs compatibility)\n",
    "# Version: 1.1.12\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum, auto\n",
    "from typing import Dict, Any, Optional, List\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# IMPORTANT: Define the logger with an explicit, consistent name\n",
    "logger = logging.getLogger(\"aei.telecom.failure.config\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = True\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# ⚠️ Custom Exception\n",
    "# ------------------------------------------------------------------------------\n",
    "class ConfigurationError(Exception):\n",
    "    \"\"\"Custom exception for configuration-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 🧩 Failure Types\n",
    "# ------------------------------------------------------------------------------\n",
    "class FailureType(Enum):\n",
    "    POWER = \"POWER\"\n",
    "    BACKHAUL = \"BACKHAUL\"\n",
    "    SOFTWARE = \"SOFTWARE\"\n",
    "    HARDWARE = \"HARDWARE\"\n",
    "    HANDOVER_FAILURE = \"HANDOVER_FAILURE\"\n",
    "    DROPPED_CALL = \"DROPPED_CALL\"\n",
    "    POWER_OUTAGE = \"POWER_OUTAGE\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 📦 Failure Event Configuration Models\n",
    "# ------------------------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class FailureEventConfig:\n",
    "    failure_id: int\n",
    "    tower_id: str\n",
    "    start_time: int  # Unix timestamp\n",
    "    duration_minutes: int\n",
    "    failure_type: str\n",
    "\n",
    "@dataclass\n",
    "class FailureEventListConfig:\n",
    "    events: List[FailureEventConfig]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 🔧 Failure Simulation Thresholds and Weights\n",
    "# ------------------------------------------------------------------------------\n",
    "@dataclass\n",
    "class FailureConfig:\n",
    "    handover_user_threshold: int = 50\n",
    "    power_outage_prob: float = 0.01\n",
    "    dropped_call_weight: float = 0.5\n",
    "    cqi_penalty_weight: float = 0.5\n",
    "    sinr_threshold: float = 3.0\n",
    "    rsrq_threshold: float = -15.0\n",
    "    cqi_threshold: float = 3.0\n",
    "    rsrp_threshold: float = -110.0\n",
    "    distance_weight: float = 0.4\n",
    "    base_failure_rate: float = 0.05\n",
    "    failure_types: List[str] = field(default_factory=lambda: [\n",
    "        \"POWER\", \"BACKHAUL\", \"SOFTWARE\", \"HANDOVER_FAILURE\", \"DROPPED_CALL\"\n",
    "    ])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 🧩 Final Combined Failure Configuration\n",
    "# ------------------------------------------------------------------------------\n",
    "@dataclass\n",
    "class AEIFailureConfig:\n",
    "    simulation: FailureConfig\n",
    "    events: Optional[FailureEventListConfig] = None\n",
    "\n",
    "class AEIFailureSimulator:\n",
    "    \"\"\"Simulates network failures based on configuration\"\"\"\n",
    "    \n",
    "    def __init__(self, config: AEIFailureConfig):\n",
    "        \"\"\"Initialize simulator with configuration\"\"\"\n",
    "        # Debug print types\n",
    "        logger.debug(\"AEIFailureSimulator Input Types:\")\n",
    "        logger.debug(\"Simulation Config:\")\n",
    "        for field, value in config.simulation.__dict__.items():\n",
    "            logger.debug(f\"{field}: {type(value)}\")\n",
    "        \n",
    "        if config.events:\n",
    "            logger.debug(\"Event Configs:\")\n",
    "            for i, event in enumerate(config.events.events, 1):\n",
    "                logger.debug(f\"Event {i}:\")\n",
    "                for field, value in event.__dict__.items():\n",
    "                    logger.debug(f\"{field}: {type(value)}\")\n",
    "        \n",
    "        # Store config\n",
    "        self.config = config\n",
    "        \n",
    "    def simulate(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Run failure simulation on input data\"\"\"\n",
    "        # Add your simulation logic here\n",
    "        return df\n",
    "\n",
    "class AEIFailureConfigManager:\n",
    "    @staticmethod\n",
    "    def _get_initial_defaults() -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"thresholds\": {\n",
    "                \"handover_user\": 50, \"sinr\": 0.0, \"rsrq\": -15.0, \"cqi\": 3\n",
    "            },\n",
    "            \"probabilities\": {\n",
    "                \"power_outage\": 0.001, \"dropped_call\": 0.5, \"cqi_penalty\": 0.5\n",
    "            },\n",
    "            \"failure_types\": [\n",
    "                \"POWER\", \"BACKHAUL\", \"SOFTWARE\", \"HARDWARE\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    _DEFAULTS = _get_initial_defaults()\n",
    "\n",
    "    def __init__(self, override_config: Optional[Dict[str, Any]] = None):\n",
    "        if not isinstance(override_config, (dict, type(None))):\n",
    "            raise ConfigurationError(f\"Override config must be a dictionary or None. Got {type(override_config).__name__}\")\n",
    "\n",
    "        self.config = AEIFailureConfigManager._deep_merge(\n",
    "            AEIFailureConfigManager._get_initial_defaults(), override_config or {}\n",
    "        )\n",
    "\n",
    "        self._validate_for_unknown_keys(self.config, self._get_config_schema())\n",
    "        self._validate_structure_and_types(self.config, self._get_config_schema())\n",
    "        self._validate_physical_constraints()\n",
    "        self._documentation = self._generate_documentation()\n",
    "        logger.debug(\"AEIFailureConfigManager initialized successfully.\")\n",
    "\n",
    "    @property\n",
    "    def documentation(self) -> str:\n",
    "        return self._documentation\n",
    "\n",
    "    def create_failure_config(self) -> \"FailureConfig\":\n",
    "        return FailureConfig(\n",
    "            handover_user_threshold=self.config[\"thresholds\"][\"handover_user\"],\n",
    "            power_outage_prob=self.config[\"probabilities\"][\"power_outage\"],\n",
    "            dropped_call_weight=self.config[\"probabilities\"][\"dropped_call\"],\n",
    "            cqi_penalty_weight=self.config[\"probabilities\"][\"cqi_penalty\"],\n",
    "            sinr_threshold=self.config[\"thresholds\"][\"sinr\"],\n",
    "            rsrq_threshold=self.config[\"thresholds\"][\"rsrq\"],\n",
    "            cqi_threshold=self.config[\"thresholds\"][\"cqi\"],\n",
    "            failure_types=self.config[\"failure_types\"]\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, filepath: str) -> \"AEIFailureConfigManager\":\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Configuration file not found: {filepath}\")\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                config_data = json.load(f)\n",
    "            logger.info(f\"Loaded configuration from JSON: {filepath}\")\n",
    "            return cls(override_config=config_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ConfigurationError(f\"Invalid JSON format in {filepath}: {e}\") from e\n",
    "        except Exception as e:\n",
    "            raise ConfigurationError(f\"Failed to load config from {filepath}: {e}\") from e\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, config_dict: Dict[str, Any]) -> \"AEIFailureConfigManager\":\n",
    "        logger.info(\"Creating AEIFailureConfigManager from dictionary.\")\n",
    "        return cls(override_config=config_dict)\n",
    "\n",
    "    def _get_config_schema(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"thresholds\": {\n",
    "                \"handover_user\": (int, float), \"sinr\": (int, float),\n",
    "                \"rsrq\": (int, float), \"cqi\": int\n",
    "            },\n",
    "            \"probabilities\": {\n",
    "                \"power_outage\": (int, float), \"dropped_call\": (int, float),\n",
    "                \"cqi_penalty\": (int, float)\n",
    "            },\n",
    "            \"failure_types\": list\n",
    "        }\n",
    "\n",
    "    def _validate_for_unknown_keys(self, config_part: Dict, schema_part: Dict, path: str = \"\"):\n",
    "        unknown_keys = [k for k in config_part if k not in schema_part]\n",
    "        if unknown_keys:\n",
    "            expected_keys_str = \", \".join(sorted(schema_part.keys()))\n",
    "            raise ConfigurationError(f\"Unknown configuration keys found at '{path}': {', '.join(unknown_keys)}. Expected keys: {expected_keys_str}.\")\n",
    "\n",
    "        for key, value in config_part.items():\n",
    "            if isinstance(value, dict) and key in schema_part and isinstance(schema_part[key], dict):\n",
    "                self._validate_for_unknown_keys(value, schema_part[key], f\"{path}{key}.\")\n",
    "\n",
    "    def _validate_structure_and_types(self, config_part: Any, schema_part: Any, path: str = \"\"):\n",
    "        if path == \"\" and not isinstance(config_part, dict):\n",
    "            raise ConfigurationError(f\"Configuration at '{path}' must be a dictionary. Got {type(config_part).__name__}.\")\n",
    "\n",
    "        if not isinstance(schema_part, dict):\n",
    "            if not isinstance(config_part, schema_part):\n",
    "                if isinstance(schema_part, tuple):\n",
    "                    expected_name = \" or \".join([t.__name__ for t in schema_part])\n",
    "                else:\n",
    "                    expected_name = schema_part.__name__\n",
    "                raise ConfigurationError(f\"'{path}' must be of type {expected_name}. Got {type(config_part).__name__}.\")\n",
    "            return\n",
    "\n",
    "        for key, expected_type in schema_part.items():\n",
    "            if key not in config_part:\n",
    "                continue\n",
    "\n",
    "            current_value = config_part[key]\n",
    "            current_path = f\"{path}{key}\" if path else key\n",
    "\n",
    "            if isinstance(expected_type, dict):\n",
    "                if not isinstance(current_value, dict):\n",
    "                    raise ConfigurationError(f\"'{current_path}' must be a dictionary, not {type(current_value).__name__}\")\n",
    "                self._validate_structure_and_types(current_value, expected_type, current_path + \".\")\n",
    "            else:\n",
    "                if not isinstance(current_value, expected_type):\n",
    "                    if isinstance(expected_type, tuple):\n",
    "                        expected_name = \" or \".join([t.__name__ for t in expected_type])\n",
    "                    else:\n",
    "                        expected_name = expected_type.__name__\n",
    "                    raise ConfigurationError(f\"'{current_path}' must be of type {expected_name}. Got {type(current_value).__name__}.\")\n",
    "\n",
    "    def _validate_physical_constraints(self):\n",
    "        probs = self.config.get(\"probabilities\", {})\n",
    "        for name, value in probs.items():\n",
    "            if not 0 <= value <= 1:\n",
    "                raise ConfigurationError(f\"'{name}' probability ({value}) must be between 0 and 1.\")\n",
    "\n",
    "        thresholds = self.config.get(\"thresholds\", {})\n",
    "        if \"handover_user\" in thresholds and thresholds[\"handover_user\"] < 0:\n",
    "            raise ConfigurationError(\"Handover user threshold cannot be negative.\")\n",
    "\n",
    "        if \"rsrq\" in thresholds:\n",
    "            if not -30 <= thresholds[\"rsrq\"] <= 0:\n",
    "                raise ConfigurationError(f\"RSRQ threshold ({thresholds['rsrq']} dB) must be between -30 and 0 dB.\")\n",
    "\n",
    "        if \"cqi\" in thresholds:\n",
    "            if not 1 <= thresholds[\"cqi\"] <= 15:\n",
    "                raise ConfigurationError(f\"CQI threshold ({thresholds['cqi']}) must be between 1 and 15.\")\n",
    "\n",
    "        failure_types = self.config.get(\"failure_types\", [])\n",
    "        for f_type_str in failure_types:\n",
    "            if f_type_str not in FailureType.__members__:\n",
    "                raise ConfigurationError(f\"Invalid failure type '{f_type_str}'.\")\n",
    "\n",
    "    def _generate_documentation(self) -> str:\n",
    "        thresholds_doc = json.dumps(self.config['thresholds'], indent=2)\n",
    "        probabilities_doc = json.dumps(self.config['probabilities'], indent=2)\n",
    "        failure_types_doc = json.dumps([ft.name for ft in FailureType], indent=2)\n",
    "\n",
    "        return f\"\"\"## AEI Failure Simulation Configuration Documentation\n",
    "\n",
    "This document outlines the current configuration for the AEI Failure Simulation System.\n",
    "\n",
    "### Thresholds\n",
    "{thresholds_doc}\n",
    "\n",
    "### Probabilities\n",
    "{probabilities_doc}\n",
    "\n",
    "### Available Failure Types\n",
    "{failure_types_doc}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _deep_merge(base: Dict, update: Dict) -> Dict:\n",
    "        for key, value in update.items():\n",
    "            if isinstance(value, dict) and key in base and isinstance(base[key], dict):\n",
    "                base[key] = AEIFailureConfigManager._deep_merge(base[key], value)\n",
    "            else:\n",
    "                base[key] = value\n",
    "        return base\n",
    "''')\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. HELPER FUNCTIONS AND MAIN LOGIC\n",
    "# ==============================================================================\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Create directory structure and write the module file.\"\"\"\n",
    "    logger.info(\"Setting up test environment\")\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "    for path_segment in [\"/aei\", \"/aei/telecom\", \"/aei/telecom/failure\"]:\n",
    "        init_path = os.path.join(\"/kaggle/working\", path_segment.lstrip('/'), \"__init__.py\")\n",
    "        open(init_path, 'a').close()\n",
    "\n",
    "    with open(CONFIG_FILE_PATH, 'w') as f:\n",
    "        f.write(failure_config_code)\n",
    "    logger.info(f\"Module saved to {CONFIG_FILE_PATH}\")\n",
    "\n",
    "def import_dynamically():\n",
    "    \"\"\"Handles path, module reloading, and dynamic import.\"\"\"\n",
    "    logger.info(\"Dynamically Importing Module\")\n",
    "    if \"/kaggle/working\" not in sys.path:\n",
    "        sys.path.append(\"/kaggle/working\")\n",
    "    \n",
    "    if MODULE_NAME in sys.modules:\n",
    "        del sys.modules[MODULE_NAME]\n",
    "    \n",
    "    spec = importlib.util.spec_from_file_location(MODULE_NAME, CONFIG_FILE_PATH)\n",
    "    if spec is None:\n",
    "        raise ImportError(f\"Could not load spec for module {MODULE_NAME}\")\n",
    "    \n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[MODULE_NAME] = config_module\n",
    "    spec.loader.exec_module(config_module)\n",
    "    return config_module\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function to set up, import, and test the module.\"\"\"\n",
    "    setup_environment()\n",
    "    config_module = import_dynamically()\n",
    "    \n",
    "    # Get the required classes\n",
    "    AEIFailureConfigManager = config_module.AEIFailureConfigManager\n",
    "    ConfigurationError = config_module.ConfigurationError\n",
    "    FailureConfig = config_module.FailureConfig\n",
    "\n",
    "    # Test default configuration\n",
    "    logger.info(\"Testing default configuration\")\n",
    "    try:\n",
    "        default_manager = AEIFailureConfigManager()\n",
    "        default_config = default_manager.create_failure_config()\n",
    "        logger.info(\"Default configuration test passed\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Default configuration test failed: {e}\")\n",
    "\n",
    "    # Test custom configuration\n",
    "    logger.info(\"Testing custom configuration\")\n",
    "    try:\n",
    "        custom_config = {\n",
    "            \"thresholds\": {\"cqi\": 10, \"sinr\": 2.5},\n",
    "            \"probabilities\": {\"dropped_call\": 0.5, \"cqi_penalty\": 0.5},\n",
    "            \"failure_types\": [\"POWER\", \"BACKHAUL\"]\n",
    "        }\n",
    "        custom_manager = AEIFailureConfigManager(override_config=custom_config)\n",
    "        custom_config_obj = custom_manager.create_failure_config()\n",
    "        logger.info(\"Custom configuration test passed\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Custom configuration test failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Script failed: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6f0693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T17:38:46.524110Z",
     "iopub.status.busy": "2025-07-21T17:38:46.523659Z",
     "iopub.status.idle": "2025-07-21T17:38:46.668189Z",
     "shell.execute_reply": "2025-07-21T17:38:46.667186Z"
    },
    "papermill": {
     "duration": 0.154816,
     "end_time": "2025-07-21T17:38:46.669907",
     "exception": false,
     "start_time": "2025-07-21T17:38:46.515091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prometheus registry cleared for testing.\n",
      "Successfully imported AEIFailureSimulator from the corrected file!\n",
      "An unexpected error occurred during testing: NONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Configure logging to see messages from the simulator\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "# Ensure necessary directories and __init__.py files exist\n",
    "os.makedirs(\"/kaggle/working/aei/telecom/failure\", exist_ok=True)\n",
    "open(\"/kaggle/working/aei/__init__.py\", \"a\").close()\n",
    "open(\"/kaggle/working/aei/telecom/__init__.py\", \"a\").close()\n",
    "open(\"/kaggle/working/aei/telecom/failure/__init__.py\", \"a\").close()\n",
    "\n",
    "# The corrected code for failure_simulator.py\n",
    "# We need to rewrite the file each time to ensure the latest version is used\n",
    "# and handle Prometheus import gracefully within the file itself.\n",
    "corrected_failure_simulator_code = '''\n",
    "# -------------------------------\n",
    "# ⚠️ AEI Telecom Failure Simulator\n",
    "# -------------------------------\n",
    "# aei/telecom/failure/failure_simulator.py\n",
    "# Author: AID Edge Inc. Network Reliability Team\n",
    "# Date: 2025-07-16\n",
    "# Version: 1.2.0 (with Enterprise SDK enhancements)\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Optional, List\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum, auto\n",
    "from functools import wraps\n",
    "from time import perf_counter\n",
    "import json # For data quality report\n",
    "\n",
    "# --- Prometheus Integration ---\n",
    "# Install via: pip install prometheus_client\n",
    "try:\n",
    "    from prometheus_client import Counter, Gauge, generate_latest, REGISTRY as PROMETHEUS_REGISTRY_GLOBAL # Import REGISTRY directly\n",
    "    PROMETHEUS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PROMETHEUS_AVAILABLE = False\n",
    "    logging.warning(\"Prometheus client not installed. Metrics will not be exported. Run 'pip install prometheus_client'\")\n",
    "\n",
    "# Import from your new config module\n",
    "from aei.telecom.failure.config import FailureConfig, FailureType, ConfigurationError, AEIFailureConfigManager\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Prometheus metrics are now initialized within the AEIFailureSimulator's __init__ method\n",
    "# to ensure the class is defined before metrics are associated with it.\n",
    "\n",
    "def timed_operation(func):\n",
    "    \"\"\"Decorator to log execution time of functions and update Prometheus gauge.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        duration = end_time - start_time\n",
    "        logger.debug(f\"Operation '{func.__name__}' completed in {duration:.4f} seconds.\")\n",
    "        \n",
    "        # Access metrics via the instance if needed, or assume they are global and initialized\n",
    "        # For simplicity, assuming global Prometheus metrics once initialized globally by the first instance.\n",
    "        if PROMETHEUS_AVAILABLE and func.__name__ == 'simulate':\n",
    "            # This depends on the global definition of sim_simulation_duration_seconds.\n",
    "            # If metrics are instance-specific, this decorator needs to be a method of the class\n",
    "            # or receive the instance and its metrics. For now, it remains global scope.\n",
    "            try:\n",
    "                # Access the class-level gauge directly\n",
    "                if hasattr(AEIFailureSimulator, '_sim_simulation_duration_seconds_gauge') and AEIFailureSimulator._sim_simulation_duration_seconds_gauge is not None:\n",
    "                    AEIFailureSimulator._sim_simulation_duration_seconds_gauge.set(duration)\n",
    "            except NameError:\n",
    "                logger.warning(\"Prometheus gauge 'sim_simulation_duration_seconds' not found or initialized for timed_operation.\")\n",
    "        \n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class AEIFailureSimulator:\n",
    "    \"\"\"\n",
    "    Enterprise-grade failure simulation for telecom networks.\n",
    "    \n",
    "    Features:\n",
    "    - Configurable failure thresholds via FailureConfig object.\n",
    "    - Detailed logging and performance monitoring.\n",
    "    - Type safety and input validation.\n",
    "    - Reproducible simulations using a random seed.\n",
    "    - Compatibility layer for existing data generation pipelines.\n",
    "    - Prometheus metrics integration for operational monitoring.\n",
    "    - (Conceptual) JSON config encryption support.\n",
    "    - (Conceptual) Data Quality Report generation.\n",
    "    - (Conceptual) Dask compatibility for large datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class-level attributes for Prometheus metrics to ensure they are defined once\n",
    "    # and shared across instances.\n",
    "    if PROMETHEUS_AVAILABLE:\n",
    "        _metrics_initialized = False\n",
    "        _sim_total_simulations_counter = None\n",
    "        _sim_failure_type_counts_counter = None\n",
    "        _sim_high_level_failure_counts_counter = None\n",
    "        _sim_avg_request_failure_rate_gauge = None\n",
    "        _sim_simulation_duration_seconds_gauge = None # Renamed for clarity and consistency\n",
    "\n",
    "    def __init__(self, seed: Optional[int] = None, config: Optional[FailureConfig] = None):\n",
    "        \"\"\"\n",
    "        Initializes the AEIFailureSimulator.\n",
    "\n",
    "        Args:\n",
    "            seed (Optional[int]): Seed for random number generation for reproducibility.\n",
    "            config (Optional[FailureConfig]): Configuration object for failure parameters.\n",
    "                                            If None, a default FailureConfig is created\n",
    "                                            using AEIFailureConfigManager's defaults.\n",
    "        \n",
    "        Raises:\n",
    "            ConfigurationError: If the provided config is invalid during internal validation.\n",
    "        \"\"\"\n",
    "        self.rng = np.random.RandomState(seed) # Initialize RNG with seed\n",
    "        \n",
    "        if config is None:\n",
    "            # If no config is provided, use the AEIFailureConfigManager to get a default one.\n",
    "            try:\n",
    "                default_config_manager = AEIFailureConfigManager()\n",
    "                self.config = default_config_manager.create_failure_config()\n",
    "            except ConfigurationError as e:\n",
    "                logger.critical(f\"Failed to load default configuration for simulator: {e}\")\n",
    "                raise # Re-raise as it's a critical setup failure\n",
    "        else:\n",
    "            if not isinstance(config, FailureConfig):\n",
    "                raise TypeError(\"Provided 'config' must be an instance of FailureConfig.\")\n",
    "            self.config = config\n",
    "        \n",
    "        self._validate_config_internal() # Validate the received/created FailureConfig\n",
    "        logger.info(f\"AEIFailureSimulator initialized with seed: {seed}, \"\n",
    "                                f\"Failure Types: {self.config.failure_types}, \"\n",
    "                                f\"Power Outage Prob: {self.config.power_outage_prob}\")\n",
    "        \n",
    "        # --- Prometheus Metrics Initialization (Moved into __init__) ---\n",
    "        if PROMETHEUS_AVAILABLE and not AEIFailureSimulator._metrics_initialized:\n",
    "            logger.info(\"Initializing Prometheus metrics for AEIFailureSimulator.\")\n",
    "            AEIFailureSimulator._sim_total_simulations_counter = Counter(\n",
    "                'aei_telecom_sim_total_simulations',\n",
    "                'Total number of telecom failure simulations run',\n",
    "                registry=PROMETHEUS_REGISTRY_GLOBAL # Explicitly use the global registry\n",
    "            )\n",
    "            AEIFailureSimulator._sim_failure_type_counts_counter = Counter(\n",
    "                'aei_telecom_sim_failure_type_total',\n",
    "                'Total count of specific failure types detected',\n",
    "                ['failure_type_detailed'],\n",
    "                registry=PROMETHEUS_REGISTRY_GLOBAL\n",
    "            )\n",
    "            AEIFailureSimulator._sim_high_level_failure_counts_counter = Counter(\n",
    "                'aei_telecom_sim_high_level_failure_total',\n",
    "                'Total count of high-level failure types assigned',\n",
    "                ['failure_type_high_level'],\n",
    "                registry=PROMETHEUS_REGISTRY_GLOBAL\n",
    "            )\n",
    "            AEIFailureSimulator._sim_avg_request_failure_rate_gauge = Gauge(\n",
    "                'aei_telecom_sim_avg_request_failure_rate',\n",
    "                'Average Request Failure Rate from the last simulation run',\n",
    "                registry=PROMETHEUS_REGISTRY_GLOBAL\n",
    "            )\n",
    "            AEIFailureSimulator._sim_simulation_duration_seconds_gauge = Gauge(\n",
    "                'aei_telecom_sim_simulation_duration_seconds',\n",
    "                'Duration of the last comprehensive simulation run',\n",
    "                registry=PROMETHEUS_REGISTRY_GLOBAL\n",
    "            )\n",
    "            AEIFailureSimulator._metrics_initialized = True # Set flag after initialization\n",
    "            logger.debug(\"Prometheus metrics initialized.\")\n",
    "\n",
    "        # Increment total simulations counter on initialization\n",
    "        if PROMETHEUS_AVAILABLE:\n",
    "            if AEIFailureSimulator._sim_total_simulations_counter: # Ensure it's initialized before incrementing\n",
    "                AEIFailureSimulator._sim_total_simulations_counter.inc()\n",
    "\n",
    "\n",
    "    def _validate_config_internal(self):\n",
    "        \"\"\"\n",
    "        Performs internal validation on the FailureConfig object.\n",
    "        This is a safeguard, as AEIFailureConfigManager should already validate.\n",
    "        \"\"\"\n",
    "        if not 0 <= self.config.power_outage_prob <= 1:\n",
    "            raise ConfigurationError(\"Power outage probability must be between 0 and 1.\")\n",
    "        if self.config.handover_user_threshold < 0:\n",
    "            raise ConfigurationError(\"Handover user threshold cannot be negative.\")\n",
    "        if not isinstance(self.config.failure_types, list) or not self.config.failure_types:\n",
    "            raise ConfigurationError(\"failure_types must be a non-empty list of strings.\")\n",
    "        \n",
    "        # Verify that all failure types listed in config are valid Enum members\n",
    "        for f_type_str in self.config.failure_types:\n",
    "            try:\n",
    "                FailureType[f_type_str]\n",
    "            except KeyError:\n",
    "                raise ConfigurationError(f\"Configured failure type '{f_type_str}' is not a valid \"\n",
    "                                         f\"FailureType enum member. Valid types: {[t.name for t in FailureType]}.\")\n",
    "        logger.debug(\"FailureConfig internally validated successfully.\")\n",
    "\n",
    "    @timed_operation\n",
    "    def simulate_failures(self, df: pd.DataFrame, failure_prob_overall: float = 0.05) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Simulates failures and assigns a high-level 'failure_type' based on simulation outcomes.\n",
    "        This method acts as an adapter for compatibility, ensuring 'failure_type' is derived\n",
    "        from detailed simulation results.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame with telecom metrics.\n",
    "            failure_prob_overall (float): An overall probability to randomly introduce generic\n",
    "                                            failure types where no specific failure is detected.\n",
    "                                            This is for compatibility and can be set to 0.0 if not needed.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with added detailed failure columns and a high-level 'failure_type'.\n",
    "        \"\"\"\n",
    "        if df.empty:\n",
    "            logger.warning(\"Received empty DataFrame for failure simulation. Returning empty DataFrame.\")\n",
    "            return df.copy()\n",
    "\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # 1. First, run the detailed simulations to get specific failure indicators\n",
    "        df_processed = self.simulate(df_processed)\n",
    "\n",
    "        # 2. Determine the high-level 'failure_type' based on the detailed simulations\n",
    "        # Initialize with NONE\n",
    "        df_processed['failure_type'] = FailureType.NONE.name\n",
    "\n",
    "        # Prioritize assigning specific failure types if they occur\n",
    "        # Ensure the order below reflects desired priority\n",
    "        df_processed.loc[df_processed['Power_Outage'] == 1, 'failure_type'] = FailureType.POWER_OUTAGE.name\n",
    "        df_processed.loc[df_processed['Handover_Failures'] == 1, 'failure_type'] = FailureType.HANDOVER_FAILURE.name\n",
    "        df_processed.loc[df_processed['Dropped_Calls'] == 1, 'failure_type'] = FailureType.DROPPED_CALL.name\n",
    "        \n",
    "        # 3. Apply generic failure types for remaining 'NONE' entries based on overall probability\n",
    "        remaining_mask = (df_processed['failure_type'] == FailureType.NONE.name)\n",
    "        if remaining_mask.any() and failure_prob_overall > 0:\n",
    "            # Generate random assignments ONLY for the `remaining_mask` rows\n",
    "            random_values = self.rng.random(size=remaining_mask.sum())\n",
    "            \n",
    "            # Create a Series from random_values < failure_prob_overall to align with remaining_mask's index\n",
    "            # This ensures proper alignment and broadcasting\n",
    "            temp_random_assign_mask = pd.Series(random_values < failure_prob_overall, index=df_processed[remaining_mask].index)\n",
    "\n",
    "            # Filter failure types that are *not* the specific ones calculated above\n",
    "            # Ensure we only pick from the `self.config.failure_types` that are enabled\n",
    "            generic_failure_types = [\n",
    "                ft for ft in self.config.failure_types\n",
    "                if ft not in [FailureType.DROPPED_CALL.name, FailureType.HANDOVER_FAILURE.name, FailureType.POWER_OUTAGE.name]\n",
    "            ]\n",
    "            \n",
    "            if generic_failure_types:\n",
    "                # Combine the masks correctly by index for the final assignment\n",
    "                final_assignment_mask = remaining_mask & temp_random_assign_mask\n",
    "                \n",
    "                # Assign chosen generic failure types to the filtered rows\n",
    "                df_processed.loc[final_assignment_mask, 'failure_type'] = \\\n",
    "                    self.rng.choice(generic_failure_types, size=final_assignment_mask.sum())\n",
    "            else:\n",
    "                logger.debug(\"No generic failure types configured to assign to 'NONE' entries.\")\n",
    "\n",
    "        logger.info(f\"High-level 'failure_type' assigned to {len(df_processed)} records.\")\n",
    "        \n",
    "        # --- Prometheus: Increment high-level failure type counts ---\n",
    "        if PROMETHEUS_AVAILABLE and AEIFailureSimulator._sim_high_level_failure_counts_counter:\n",
    "            for f_type in df_processed['failure_type'].unique():\n",
    "                AEIFailureSimulator._sim_high_level_failure_counts_counter.labels(f_type).inc(df_processed[df_processed['failure_type'] == f_type].shape[0])\n",
    "\n",
    "        return df_processed\n",
    "\n",
    "    @timed_operation\n",
    "    def simulate(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Simulate network failures on telecom data. This is the comprehensive method\n",
    "        that adds detailed failure indicator columns.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing network metrics (RSRP, RSRQ, SINR, CQI, device_count).\n",
    "                               Note: \"User Count\" is expected to be \"device_count\" from TelecomDataGenerator.\n",
    "                               \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with added binary failure columns:\n",
    "                            - Dropped_Calls (binary: 0 or 1)\n",
    "                            - Handover_Failures (binary: 0 or 1)\n",
    "                            - Power_Outage (binary: 0 or 1)\n",
    "                            - Request_Failure_Rate (float: 0-100)\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If required columns are missing in the input DataFrame.\n",
    "            Exception: For other unexpected errors during simulation.\n",
    "        \"\"\"\n",
    "        self._validate_input(df)\n",
    "        \n",
    "        try:\n",
    "            df_processed = df.copy()\n",
    "            df_processed[\"Dropped_Calls\"] = self._calculate_dropped_calls(df_processed)\n",
    "            df_processed[\"Handover_Failures\"] = self._calculate_handover_failures(df_processed)\n",
    "            df_processed[\"Power_Outage\"] = self._simulate_power_outages(len(df_processed))\n",
    "            df_processed[\"Request_Failure_Rate\"] = self._calculate_failure_rate(df_processed)\n",
    "            \n",
    "            logger.info(f\"Simulated detailed failures on {len(df_processed)} records.\")\n",
    "            self._log_failure_stats(df_processed)\n",
    "\n",
    "            # --- Prometheus: Update detailed failure type counts ---\n",
    "            if PROMETHEUS_AVAILABLE and AEIFailureSimulator._sim_failure_type_counts_counter and AEIFailureSimulator._sim_avg_request_failure_rate_gauge:\n",
    "                AEIFailureSimulator._sim_failure_type_counts_counter.labels(FailureType.DROPPED_CALL.name).inc(df_processed[\"Dropped_Calls\"].sum())\n",
    "                AEIFailureSimulator._sim_failure_type_counts_counter.labels(FailureType.HANDOVER_FAILURE.name).inc(df_processed[\"Handover_Failures\"].sum())\n",
    "                AEIFailureSimulator._sim_failure_type_counts_counter.labels(FailureType.POWER_OUTAGE.name).inc(df_processed[\"Power_Outage\"].sum())\n",
    "                \n",
    "                if not df_processed.empty:\n",
    "                    AEIFailureSimulator._sim_avg_request_failure_rate_gauge.set(df_processed[\"Request_Failure_Rate\"].mean())\n",
    "                else:\n",
    "                    AEIFailureSimulator._sim_avg_request_failure_rate_gauge.set(0) # Reset if no data\n",
    "\n",
    "            return df_processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Comprehensive failure simulation error: {str(e)}\", exc_info=True)\n",
    "            raise # Re-raise the exception after logging for upstream handling\n",
    "            \n",
    "    def _validate_input(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Validate input DataFrame structure before simulation.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): The input DataFrame to validate.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If required columns are missing.\n",
    "        \"\"\"\n",
    "        required_columns = {\"RSRP\", \"RSRQ\", \"SINR\", \"CQI\", \"device_count\"}\n",
    "        missing = required_columns - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns for failure simulation: {missing}. \"\n",
    "                             f\"Required: {required_columns}, Found: {set(df.columns)}\")\n",
    "        logger.debug(\"Input DataFrame validated for failure simulation.\")\n",
    "            \n",
    "    def _calculate_dropped_calls(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate dropped calls based on signal quality (SINR and RSRQ thresholds).\n",
    "        \"\"\"\n",
    "        sinr = pd.to_numeric(df[\"SINR\"], errors='coerce').fillna(self.config.sinr_threshold - 1) # Treat NaNs as bad signal\n",
    "        rsrq = pd.to_numeric(df[\"RSRQ\"], errors='coerce').fillna(self.config.rsrq_threshold - 1) # Treat NaNs as bad signal\n",
    "        return ((sinr < self.config.sinr_threshold) | \n",
    "                (rsrq < self.config.rsrq_threshold)).astype(int)\n",
    "    \n",
    "    def _calculate_handover_failures(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate handover failures based on low CQI and high device count.\n",
    "        \"\"\"\n",
    "        cqi = pd.to_numeric(df[\"CQI\"], errors='coerce').fillna(self.config.cqi_threshold - 1) # Treat NaNs as bad CQI\n",
    "        device_count = pd.to_numeric(df[\"device_count\"], errors='coerce').fillna(0)\n",
    "        return ((cqi < self.config.cqi_threshold) & \n",
    "                (device_count > self.config.handover_user_threshold)).astype(int)\n",
    "    \n",
    "    def _simulate_power_outages(self, size: int) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Simulate random power outages based on a global probability.\n",
    "        \"\"\"\n",
    "        return pd.Series(self.rng.rand(size) < self.config.power_outage_prob).astype(int)\n",
    "    \n",
    "    def _calculate_failure_rate(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate a composite Request Failure Rate metric based on dropped calls and CQI.\n",
    "        The rate is clipped between 0 and 100.\n",
    "        \"\"\"\n",
    "        cqi = pd.to_numeric(df[\"CQI\"], errors='coerce').fillna(1) # Fill NaN CQI with 1 to avoid division by zero or large penalty\n",
    "        \n",
    "        # Normalize CQI to a 0-1 scale, then invert for penalty (lower CQI = higher penalty)\n",
    "        # Assuming CQI ranges from 1 to 15 based on standard definition\n",
    "        cqi_normalized_penalty = 1 - ((cqi - 1) / 14) # If CQI is 1, penalty is 1. If CQI is 15, penalty is 0.\n",
    "        cqi_normalized_penalty = np.clip(cqi_normalized_penalty, 0, 1) # Ensure it's strictly between 0 and 1\n",
    "\n",
    "        composite_rate = (self.config.dropped_call_weight * df[\"Dropped_Calls\"] * 100 +\n",
    "                          self.config.cqi_penalty_weight * cqi_normalized_penalty * 100)\n",
    "        \n",
    "        return np.clip(composite_rate, 0, 100) # Clip the final rate between 0 and 100\n",
    "    \n",
    "    def _log_failure_stats(self, df: pd.DataFrame):\n",
    "        \"\"\"Log statistics about simulated failures.\"\"\"\n",
    "        if df.empty:\n",
    "            logger.info(\"No data to log failure statistics for.\")\n",
    "            return\n",
    "\n",
    "        stats = {\n",
    "            FailureType.DROPPED_CALL: df[\"Dropped_Calls\"].sum(),\n",
    "            FailureType.HANDOVER_FAILURE: df[\"Handover_Failures\"].sum(),\n",
    "            FailureType.POWER_OUTAGE: df[\"Power_Outage\"].sum()\n",
    "        }\n",
    "        \n",
    "        total_records = len(df)\n",
    "        for failure_type, count in stats.items():\n",
    "            rate = (count / total_records * 100) if total_records > 0 else 0.0\n",
    "            logger.info(f\"{failure_type.name}: {count} occurrences ({rate:.2f}%)\")\n",
    "        \n",
    "        # Log distribution of the high-level 'failure_type'\n",
    "        if 'failure_type' in df.columns:\n",
    "            logger.info(\"High-level 'failure_type' distribution:\")\n",
    "            type_counts = df['failure_type'].value_counts()\n",
    "            for f_type, count in type_counts.items():\n",
    "                rate = (count / total_records * 100) if total_records > 0 else 0.0\n",
    "                logger.info(f\"  - {f_type}: {count} ({rate:.2f}%)\")\n",
    "\n",
    "    # --- Enterprise-Level SDK Enhancements (Conceptual/Placeholder Methods) ---\n",
    "\n",
    "    def generate_data_quality_report(self, df_simulated: pd.DataFrame, output_path: str = \"data_quality_report.json\"):\n",
    "        \"\"\"\n",
    "        Generates a basic data quality report summarizing simulation outcomes.\n",
    "        For an enterprise SDK, this would be much more detailed (e.g., HTML, visual summaries).\n",
    "        \n",
    "        Args:\n",
    "            df_simulated (pd.DataFrame): The DataFrame after simulation.\n",
    "            output_path (str): Path to save the report (e.g., JSON, HTML).\n",
    "        \"\"\"\n",
    "        if df_simulated.empty:\n",
    "            logger.warning(\"Cannot generate data quality report for an empty DataFrame.\")\n",
    "            return\n",
    "\n",
    "        report_summary = {\n",
    "            \"total_records\": len(df_simulated),\n",
    "            \"simulated_timestamp_utc\": pd.Timestamp.now(tz='UTC').isoformat(),\n",
    "            \"failure_counts\": {},\n",
    "            \"failure_percentages\": {},\n",
    "            \"request_failure_rate_stats\": {\n",
    "                \"mean\": df_simulated[\"Request_Failure_Rate\"].mean(),\n",
    "                \"median\": df_simulated[\"Request_Failure_Rate\"].median(),\n",
    "                \"std\": df_simulated[\"Request_Failure_Rate\"].std(),\n",
    "                \"min\": df_simulated[\"Request_Failure_Rate\"].min(),\n",
    "                \"max\": df_simulated[\"Request_Failure_Rate\"].max(),\n",
    "            },\n",
    "            \"high_level_failure_type_distribution\": df_simulated['failure_type'].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "        detailed_failure_columns = [\"Dropped_Calls\", \"Handover_Failures\", \"Power_Outage\"]\n",
    "        for col in detailed_failure_columns:\n",
    "            if col in df_simulated.columns:\n",
    "                count = df_simulated[col].sum()\n",
    "                report_summary[\"failure_counts\"][col] = count\n",
    "                report_summary[\"failure_percentages\"][col] = (count / len(df_simulated) * 100) if len(df_simulated) > 0 else 0.0\n",
    "        \n",
    "        try:\n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(report_summary, f, indent=4)\n",
    "            logger.info(f\"Data quality report saved to {output_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save data quality report: {e}\", exc_info=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def decrypt_config_json(encrypted_filepath: str, decryption_key: bytes) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Conceptual method for decrypting a JSON configuration file.\n",
    "        This would involve a proper cryptography library (e.g., PyCryptodome or cryptography.fernet).\n",
    "        \n",
    "        Args:\n",
    "            encrypted_filepath (str): Path to the encrypted JSON file.\n",
    "            decryption_key (bytes): The decryption key.\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, Any]: The decrypted configuration dictionary.\n",
    "            \n",
    "        Raises:\n",
    "            NotImplementedError: As full encryption/decryption is complex and not fully implemented here.\n",
    "            \n",
    "        Example (conceptual):\n",
    "            from cryptography.fernet import Fernet\n",
    "            # key = Fernet.generate_key() # Generate once, store securely\n",
    "            # f = Fernet(key)\n",
    "            # encrypted_data = f.encrypt(json.dumps(config_dict).encode())\n",
    "            # with open(filepath, 'wb') as file: file.write(encrypted_data)\n",
    "            \n",
    "            # To decrypt:\n",
    "            # with open(encrypted_filepath, 'rb') as file: encrypted_content = file.read()\n",
    "            # decrypted_bytes = f.decrypt(encrypted_content)\n",
    "            # return json.loads(decrypted_bytes.decode())\n",
    "        \"\"\"\n",
    "        logger.warning(\"Decryption functionality is conceptual and not fully implemented.\")\n",
    "        raise NotImplementedError(\"JSON config decryption requires a robust key management and cryptography implementation.\")\n",
    "\n",
    "    def process_with_dask(self, dask_dataframe) -> Any: # Returns a Dask DataFrame conceptually\n",
    "        \"\"\"\n",
    "        Conceptual method to process a Dask DataFrame.\n",
    "        This would require adapting _calculate_dropped_calls, _calculate_handover_failures, etc.,\n",
    "        to use Dask DataFrame operations directly or via Dask's apply/map_partitions.\n",
    "        \n",
    "        Args:\n",
    "            dask_dataframe: A Dask DataFrame with required columns.\n",
    "            \n",
    "        Returns:\n",
    "            A Dask DataFrame with simulated failures.\n",
    "            \n",
    "        Raises:\n",
    "            NotImplementedError: As full Dask integration requires significant refactoring.\n",
    "        \"\"\"\n",
    "        logger.warning(\"Dask integration is conceptual and not fully implemented.\")\n",
    "        # Example of how you might start:\n",
    "        # if not hasattr(dask_dataframe, 'dask'):\n",
    "        #     raise TypeError(\"Input must be a Dask DataFrame.\")\n",
    "        #\n",
    "        # dask_dataframe_processed = dask_dataframe.copy()\n",
    "        # dask_dataframe_processed[\"Dropped_Calls\"] = dask_dataframe_processed.apply(\n",
    "        #     lambda row: self._calculate_dropped_calls(pd.DataFrame([row])), axis=1, meta=('Dropped_Calls', int)\n",
    "        # )\n",
    "        # This is a simplified example, direct dask operations are better for performance.\n",
    "        \n",
    "        raise NotImplementedError(\"Dask compatibility requires significant refactoring of core calculation methods to be Dask-aware.\")\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open(\"/kaggle/working/aei/telecom/failure/failure_simulator.py\", \"w\") as f:\n",
    "    f.write(corrected_failure_simulator_code)\n",
    "\n",
    "# Add /kaggle/working to sys.path so Python can find the aei package\n",
    "if \"/kaggle/working\" not in sys.path:\n",
    "    sys.path.append(\"/kaggle/working\")\n",
    "\n",
    "# Reload the module to ensure changes are picked up, or remove from sys.modules\n",
    "# This is crucial in interactive environments where modules are cached.\n",
    "if 'aei.telecom.failure.failure_simulator' in sys.modules:\n",
    "    del sys.modules['aei.telecom.failure.failure_simulator']\n",
    "if 'aei.telecom.failure.config' in sys.modules:\n",
    "    del sys.modules['aei.telecom.failure.config']\n",
    "\n",
    "\n",
    "# Import the necessary components AFTER deleting from sys.modules if they were loaded before\n",
    "from aei.telecom.failure.config import AEIFailureConfigManager, FailureConfig, FailureType, ConfigurationError\n",
    "from aei.telecom.failure.failure_simulator import AEIFailureSimulator, PROMETHEUS_AVAILABLE\n",
    "\n",
    "# If Prometheus is available, ensure its registry is clean for this run\n",
    "if PROMETHEUS_AVAILABLE:\n",
    "    from prometheus_client import REGISTRY, PROCESS_COLLECTOR, PLATFORM_COLLECTOR\n",
    "\n",
    "    # Clear the default registry for testing\n",
    "    # This is a common workaround for older prometheus_client versions\n",
    "    # and effectively removes all metrics from the default registry.\n",
    "    if hasattr(REGISTRY, '_names_to_collectors'):\n",
    "        REGISTRY._names_to_collectors.clear()\n",
    "    if hasattr(REGISTRY, '_collector_to_names'):\n",
    "        REGISTRY._collector_to_names.clear()\n",
    "    \n",
    "    # Also unregister default collectors explicitly, handling KeyError\n",
    "    try:\n",
    "        REGISTRY.unregister(PROCESS_COLLECTOR)\n",
    "    except KeyError: # Collector is not registered (prometheus_client 0.9.0 and above)\n",
    "        pass\n",
    "    except ValueError: # Collector is not registered (older prometheus_client versions might raise ValueError)\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not unregister PROCESS_COLLECTOR: {e}\")\n",
    "\n",
    "    try:\n",
    "        REGISTRY.unregister(PLATFORM_COLLECTOR)\n",
    "    except KeyError: # Collector is not registered\n",
    "        pass\n",
    "    except ValueError: # Collector is not registered\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not unregister PLATFORM_COLLECTOR: {e}\")\n",
    "\n",
    "    print(\"Prometheus registry cleared for testing.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"Successfully imported AEIFailureSimulator from the corrected file!\")\n",
    "\n",
    "    # Example test DataFrame (ensure it has required columns)\n",
    "    test_df = pd.DataFrame({\n",
    "        'RSRP': np.random.uniform(-100, -50, 10),\n",
    "        'RSRQ': np.random.uniform(-20, -5, 10),\n",
    "        'SINR': np.random.uniform(-5, 25, 10),\n",
    "        'CQI': np.random.randint(1, 16, 10),\n",
    "        'device_count': np.random.randint(10, 100, 10)\n",
    "    })\n",
    "\n",
    "    # Create a custom config using AEIFailureConfigManager\n",
    "    custom_config_manager = AEIFailureConfigManager.from_dict({\n",
    "        \"thresholds\": {\n",
    "            \"handover_user\": 70,\n",
    "            \"sinr\": -3.0,\n",
    "            \"rsrq\": -18.0,\n",
    "            \"cqi\": 2\n",
    "        },\n",
    "        \"probabilities\": {\n",
    "            \"power_outage\": 0.5, # High probability for testing\n",
    "            \"dropped_call\": 0.5,\n",
    "            \"cqi_penalty\": 0.5\n",
    "        },\n",
    "        # Use the names of the FailureType enum members as strings\n",
    "        \"failure_types\": [\n",
    "            FailureType.POWER.name,\n",
    "            FailureType.SOFTWARE.name,\n",
    "            FailureType.HARDWARE.name # Add a few more generic types\n",
    "        ]\n",
    "    })\n",
    "    custom_failure_config = custom_config_manager.create_failure_config()\n",
    "\n",
    "    # Initialize simulator with the created config\n",
    "    simulator = AEIFailureSimulator(seed=42, config=custom_failure_config)\n",
    "    result_df = simulator.simulate_failures(test_df, failure_prob_overall=0.3)\n",
    "\n",
    "    print(\"\\nSample generated failures:\")\n",
    "    print(result_df[['RSRP', 'SINR', 'CQI', 'device_count', 'failure_type', \n",
    "                     'Dropped_Calls', 'Handover_Failures', 'Power_Outage', 'Request_Failure_Rate']].head())\n",
    "    print(\"\\nFailure Type Distribution (from simulate_failures):\")\n",
    "    print(result_df['failure_type'].value_counts())\n",
    "\n",
    "    # Generate a data quality report\n",
    "    report_path = \"/kaggle/working/data_quality_report.json\"\n",
    "    simulator.generate_data_quality_report(result_df, output_path=report_path)\n",
    "    print(f\"\\nData quality report generated at: {report_path}\")\n",
    "\n",
    "    # Optionally, print Prometheus metrics if PROMETHEUS_AVAILABLE\n",
    "    if PROMETHEUS_AVAILABLE:\n",
    "        from prometheus_client import generate_latest\n",
    "        print(\"\\nPrometheus Metrics:\")\n",
    "        print(generate_latest().decode('utf-8'))\n",
    "\n",
    "\n",
    "except ConfigurationError as e:\n",
    "    print(f\"Configuration Error during test setup: {e}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing AEIFailureSimulator: {e}. Make sure the file is saved correctly and __init__.py files are present.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during testing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e290e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T17:38:46.685332Z",
     "iopub.status.busy": "2025-07-21T17:38:46.684969Z",
     "iopub.status.idle": "2025-07-21T17:38:46.885881Z",
     "shell.execute_reply": "2025-07-21T17:38:46.884744Z"
    },
    "papermill": {
     "duration": 0.211389,
     "end_time": "2025-07-21T17:38:46.887705",
     "exception": false,
     "start_time": "2025-07-21T17:38:46.676316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,757 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,759 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,760 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 16\n",
      "2025-07-21 17:38:46,761 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 0\n",
      "2025-07-21 17:38:46,762 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,764 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,767 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,768 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,769 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,771 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,773 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,774 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,775 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,776 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,777 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,779 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,780 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,781 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,782 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,783 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,785 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,787 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,789 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,791 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,793 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,794 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,794 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,796 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,798 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,799 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,800 - aei.telecom.failure.config - INFO - Creating AEIFailureConfigManager from dictionary.\n",
      "2025-07-21 17:38:46,801 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,801 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,802 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,804 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,807 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,808 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,810 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,811 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,813 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,814 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,816 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,817 - aei.telecom.failure.config - INFO - Loaded configuration from JSON: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,818 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,819 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,820 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,822 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,823 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,825 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,826 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,828 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,829 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,831 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,832 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,834 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,835 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,838 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,839 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,841 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,843 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,844 - aei.telecom.failure.config - DEBUG - CQI validation check: thresholds['cqi'] is 3\n",
      "2025-07-21 17:38:46,844 - aei.telecom.failure.config - DEBUG - AEIFailureConfigManager initialized successfully.\n",
      "2025-07-21 17:38:46,845 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,847 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,849 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,850 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,852 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,853 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,854 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,856 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,858 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,860 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,862 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,863 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,865 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,866 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,868 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,870 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21 17:38:46,871 - __main__ - DEBUG - Added a StreamHandler to the root logger for general test visibility.\n",
      "2025-07-21 17:38:46,873 - root - DEBUG - Created temporary config file: /kaggle/working/temp_test_config.json\n",
      "2025-07-21 17:38:46,875 - root - DEBUG - Removed temporary config file: /kaggle/working/temp_test_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 21 tests in 0.123s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import unittest\n",
    "import json\n",
    "import logging\n",
    "import textwrap\n",
    "import importlib.util\n",
    "import shutil\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "# Configure logging for the test runner script\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODULE_NAME = \"aei.telecom.failure.config\"\n",
    "BASE_DIR = \"/kaggle/working/aei/telecom/failure\"\n",
    "CONFIG_FILE_PATH = os.path.join(BASE_DIR, \"config.py\")\n",
    "project_root = \"/kaggle/working\"\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    logger.info(f\"Added {project_root} to sys.path.\")\n",
    "\n",
    "def cleanup_environment():\n",
    "    \"\"\"Removes created directories and files, including pycache.\"\"\"\n",
    "    logger.info(\"--- 🗑️ Cleaning up previous environment ---\")\n",
    "    if os.path.exists(os.path.join(project_root, \"aei\")):\n",
    "        shutil.rmtree(os.path.join(project_root, \"aei\"), ignore_errors=True)\n",
    "        logger.info(\"Removed old 'aei' directory.\")\n",
    "    if os.path.exists(os.path.join(project_root, \"temp_test_config.json\")):\n",
    "        os.remove(os.path.join(project_root, \"temp_test_config.json\"))\n",
    "        logger.info(\"Removed old 'temp_test_config.json'.\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(project_root):\n",
    "        if '__pycache__' in dirs:\n",
    "            shutil.rmtree(os.path.join(root, '__pycache__'), ignore_errors=True)\n",
    "            logger.info(f\"Removed __pycache__ in {root}.\")\n",
    "    \n",
    "    for module in list(sys.modules.keys()):\n",
    "        if module.startswith('aei.telecom.failure') or module == MODULE_NAME:\n",
    "            if module in sys.modules and hasattr(sys.modules[module], 'logger'):\n",
    "                mod_logger = sys.modules[module].logger\n",
    "                for handler in list(mod_logger.handlers):\n",
    "                    mod_logger.removeHandler(handler)\n",
    "                mod_logger.propagate = True\n",
    "                mod_logger.setLevel(logging.NOTSET)\n",
    "            del sys.modules[module]\n",
    "            logger.debug(f\"Cleanup: Cleared '{module}' from sys.modules.\")\n",
    "\n",
    "    target_logger = logging.getLogger(\"aei.telecom.failure.config\")\n",
    "    for handler in list(target_logger.handlers):\n",
    "        target_logger.removeHandler(handler)\n",
    "    target_logger.propagate = True\n",
    "    target_logger.setLevel(logging.NOTSET)\n",
    "\n",
    "    root_logger = logging.getLogger()\n",
    "    for handler in list(root_logger.handlers):\n",
    "        root_logger.removeHandler(handler)\n",
    "    root_logger.setLevel(logging.WARNING)\n",
    "\n",
    "    if hasattr(logging.Logger, 'manager') and hasattr(logging.Logger.manager, 'loggerDict'):\n",
    "        for key in list(logging.Logger.manager.loggerDict.keys()):\n",
    "            if key.startswith('aei.telecom.failure') or key == MODULE_NAME:\n",
    "                if isinstance(logging.Logger.manager.loggerDict[key], logging.Logger):\n",
    "                    temp_logger = logging.Logger.manager.loggerDict[key]\n",
    "                    for handler in list(temp_logger.handlers):\n",
    "                        temp_logger.removeHandler(handler)\n",
    "                del logging.Logger.manager.loggerDict[key]\n",
    "                logger.debug(f\"Cleanup: Cleared logger '{key}' from manager.loggerDict.\")\n",
    "\n",
    "cleanup_environment()\n",
    "\n",
    "def setup_module_environment():\n",
    "    \"\"\"Create directory structure and write the module file.\"\"\"\n",
    "    logger.info(\"--- ⚙️ Setting up module environment ---\")\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "    for path_segment in [\"/aei\", \"/aei/telecom\", \"/aei/telecom/failure\"]:\n",
    "        init_path = os.path.join(project_root, path_segment.lstrip('/'), \"__init__.py\")\n",
    "        os.makedirs(os.path.dirname(init_path), exist_ok=True)\n",
    "        if not os.path.exists(init_path):\n",
    "            open(init_path, \"a\").close()\n",
    "            logger.debug(f\"Created {init_path}\")\n",
    "    \n",
    "    failure_config_code = textwrap.dedent('''\n",
    "# -------------------------------\n",
    "# ⚠️ AEI Failure Configuration Manager\n",
    "# -------------------------------\n",
    "# aei/telecom/failure/config.py\n",
    "# Author: AID Edge Inc. Network Reliability Team\n",
    "# Date: 2025-07-16 (Cleaned logger configuration for assertLogs compatibility)\n",
    "# Version: 1.1.12\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum, auto\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(\"aei.telecom.failure.config\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = True\n",
    "\n",
    "class ConfigurationError(Exception):\n",
    "    \"\"\"Custom exception for configuration-related errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class FailureType(Enum):\n",
    "    POWER = \"POWER\"\n",
    "    BACKHAUL = \"BACKHAUL\"\n",
    "    SOFTWARE = \"SOFTWARE\"\n",
    "    HARDWARE = \"HARDWARE\"\n",
    "    HANDOVER_FAILURE = \"HANDOVER_FAILURE\"\n",
    "    DROPPED_CALL = \"DROPPED_CALL\"\n",
    "    POWER_OUTAGE = \"POWER_OUTAGE\"  \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FailureEventConfig:\n",
    "    failure_id: int\n",
    "    tower_id: str\n",
    "    start_time: int  # Unix timestamp\n",
    "    duration_minutes: int\n",
    "    failure_type: str\n",
    "\n",
    "@dataclass\n",
    "class FailureEventListConfig:\n",
    "    events: List[FailureEventConfig]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FailureConfig:\n",
    "    handover_user_threshold: int = 50\n",
    "    power_outage_prob: float = 0.01\n",
    "    dropped_call_weight: float = 0.5\n",
    "    cqi_penalty_weight: float = 0.5\n",
    "    sinr_threshold: float = 3.0\n",
    "    rsrq_threshold: float = -15.0\n",
    "    cqi_threshold: float = 3.0\n",
    "    rsrp_threshold: float = -110.0\n",
    "    distance_weight: float = 0.4\n",
    "    base_failure_rate: float = 0.05\n",
    "    failure_types: List[str] = field(default_factory=lambda: [\n",
    "        \"POWER\",\n",
    "        \"BACKHAUL\",\n",
    "        \"SOFTWARE\",\n",
    "        \"HANDOVER_FAILURE\",\n",
    "        \"DROPPED_CALL\"\n",
    "    ])\n",
    "\n",
    "@dataclass\n",
    "class AEIFailureConfig:\n",
    "    simulation: FailureConfig\n",
    "    events: Optional[FailureEventListConfig] = None\n",
    "\n",
    "class AEIFailureConfigManager:\n",
    "    @staticmethod\n",
    "    def _get_initial_defaults() -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"thresholds\": {\n",
    "                \"handover_user\": 50, \"sinr\": 0.0, \"rsrq\": -15.0, \"cqi\": 3\n",
    "            },\n",
    "            \"probabilities\": {\n",
    "                \"power_outage\": 0.001, \"dropped_call\": 0.5, \"cqi_penalty\": 0.5\n",
    "            },\n",
    "            \"failure_types\": [\n",
    "                \"POWER\", \"BACKHAUL\",\n",
    "                \"SOFTWARE\", \"HARDWARE\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    _DEFAULTS = _get_initial_defaults()\n",
    "\n",
    "    def __init__(self, override_config: Optional[Dict[str, Any]] = None):\n",
    "        if not isinstance(override_config, (dict, type(None))):\n",
    "            raise ConfigurationError(f\"Override config must be a dictionary or None. Got {type(override_config).__name__}.\")\n",
    "\n",
    "        self.config = AEIFailureConfigManager._deep_merge(\n",
    "            AEIFailureConfigManager._get_initial_defaults(), override_config or {}\n",
    "        )\n",
    "\n",
    "        self._validate_for_unknown_keys(self.config, self._get_config_schema())\n",
    "        self._validate_structure_and_types(self.config, self._get_config_schema())\n",
    "        self._validate_physical_constraints()\n",
    "        self._documentation = self._generate_documentation()\n",
    "        logger.debug(\"AEIFailureConfigManager initialized successfully.\")\n",
    "\n",
    "    @property\n",
    "    def documentation(self) -> str:\n",
    "        return self._documentation\n",
    "\n",
    "    def create_failure_config(self) -> \"FailureConfig\":\n",
    "        return FailureConfig(\n",
    "            handover_user_threshold=self.config[\"thresholds\"][\"handover_user\"],\n",
    "            power_outage_prob=self.config[\"probabilities\"][\"power_outage\"],\n",
    "            dropped_call_weight=self.config[\"probabilities\"][\"dropped_call\"],\n",
    "            cqi_penalty_weight=self.config[\"probabilities\"][\"cqi_penalty\"],\n",
    "            sinr_threshold=self.config[\"thresholds\"][\"sinr\"],\n",
    "            rsrq_threshold=self.config[\"thresholds\"][\"rsrq\"],\n",
    "            cqi_threshold=self.config[\"thresholds\"][\"cqi\"],\n",
    "            failure_types=self.config[\"failure_types\"]\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, filepath: str) -> \"AEIFailureConfigManager\":\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Configuration file not found: {filepath}\")\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                config_data = json.load(f)\n",
    "            logger.info(f\"Loaded configuration from JSON: {filepath}\")\n",
    "            return cls(override_config=config_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ConfigurationError(f\"Invalid JSON format in {filepath}: {e}\") from e\n",
    "        except Exception as e:\n",
    "            raise ConfigurationError(f\"Failed to load config from {filepath}: {e}\") from e\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, config_dict: Dict[str, Any]) -> \"AEIFailureConfigManager\":\n",
    "        logger.info(\"Creating AEIFailureConfigManager from dictionary.\")\n",
    "        return cls(override_config=config_dict)\n",
    "\n",
    "    def _get_config_schema(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"thresholds\": {\n",
    "                \"handover_user\": (int, float), \"sinr\": (int, float),\n",
    "                \"rsrq\": (int, float), \"cqi\": int\n",
    "            },\n",
    "            \"probabilities\": {\n",
    "                \"power_outage\": (int, float), \"dropped_call\": (int, float),\n",
    "                \"cqi_penalty\": (int, float)\n",
    "            },\n",
    "            \"failure_types\": list\n",
    "        }\n",
    "\n",
    "    def _validate_for_unknown_keys(self, config_part: Dict, schema_part: Dict, path: str = \"\"):\n",
    "        unknown_keys = [k for k in config_part if k not in schema_part]\n",
    "        if unknown_keys:\n",
    "            expected_keys_str = \", \".join(sorted(schema_part.keys()))\n",
    "            raise ConfigurationError(f\"Unknown configuration keys found at '{path}': {', '.join(unknown_keys)}. Expected keys: {expected_keys_str}.\")\n",
    "\n",
    "        for key, value in config_part.items():\n",
    "            if isinstance(value, dict) and key in schema_part and isinstance(schema_part[key], dict):\n",
    "                self._validate_for_unknown_keys(value, schema_part[key], f\"{path}{key}.\")\n",
    "\n",
    "    def _validate_structure_and_types(self, config_part: Any, schema_part: Any, path: str = \"\"):\n",
    "        if path == \"\" and not isinstance(config_part, dict):\n",
    "            raise ConfigurationError(f\"Configuration at '{path}' must be a dictionary. Got {type(config_part).__name__}.\")\n",
    "\n",
    "        if not isinstance(schema_part, dict):\n",
    "            if not isinstance(config_part, schema_part):\n",
    "                if isinstance(schema_part, tuple):\n",
    "                    expected_name = \" or \".join([t.__name__ for t in schema_part])\n",
    "                else:\n",
    "                    expected_name = schema_part.__name__\n",
    "                raise ConfigurationError(f\"'{path}' must be of type {expected_name}. Got {type(config_part).__name__}.\")\n",
    "            return\n",
    "\n",
    "        for key, expected_type in schema_part.items():\n",
    "            if key not in config_part:\n",
    "                continue\n",
    "\n",
    "            current_value = config_part[key]\n",
    "            current_path = f\"{path}{key}\" if path else key\n",
    "\n",
    "            if isinstance(expected_type, dict):\n",
    "                if not isinstance(current_value, dict):\n",
    "                    raise ConfigurationError(f\"'{current_path}' must be a dictionary, not {type(current_value).__name__}\")\n",
    "                self._validate_structure_and_types(current_value, expected_type, current_path + \".\")\n",
    "            else:\n",
    "                if not isinstance(current_value, expected_type):\n",
    "                    if isinstance(expected_type, tuple):\n",
    "                        expected_name = \" or \".join([t.__name__ for t in expected_type])\n",
    "                    else:\n",
    "                        expected_name = expected_type.__name__\n",
    "                    raise ConfigurationError(f\"'{current_path}' must be of type {expected_name}. Got {type(current_value).__name__}.\")\n",
    "\n",
    "    def _validate_physical_constraints(self):\n",
    "        probs = self.config.get(\"probabilities\", {})\n",
    "        for name, value in probs.items():\n",
    "            if not 0 <= value <= 1:\n",
    "                raise ConfigurationError(f\"'{name}' probability ({value}) must be between 0 and 1.\")\n",
    "\n",
    "        thresholds = self.config.get(\"thresholds\", {})\n",
    "        if \"handover_user\" in thresholds and thresholds[\"handover_user\"] < 0:\n",
    "            raise ConfigurationError(\"Handover user threshold cannot be negative.\")\n",
    "\n",
    "        if \"rsrq\" in thresholds:\n",
    "            if not -30 <= thresholds[\"rsrq\"] <= 0:\n",
    "                raise ConfigurationError(f\"RSRQ threshold ({thresholds['rsrq']} dB) must be between -30 and 0 dB.\")\n",
    "\n",
    "        if \"cqi\" in thresholds:\n",
    "            logger.debug(f\"CQI validation check: thresholds['cqi'] is {thresholds['cqi']}\")\n",
    "            if not 1 <= thresholds[\"cqi\"] <= 15:\n",
    "                raise ConfigurationError(f\"CQI threshold ({thresholds['cqi']}) must be between 1 and 15.\")\n",
    "\n",
    "        if \"sinr\" in thresholds and thresholds[\"sinr\"] > 5.0:\n",
    "            logger.warning(f\"SINR threshold ({thresholds['sinr']} dB) is positive and quite high. Consider typical SINR values are often negative for poor conditions.\")\n",
    "\n",
    "        failure_types = self.config.get(\"failure_types\", [])\n",
    "        for f_type_str in failure_types:\n",
    "            if f_type_str not in [ft.value for ft in FailureType]:\n",
    "                raise ConfigurationError(f\"Invalid failure type '{f_type_str}'.\")\n",
    "\n",
    "        if \"dropped_call\" in probs and \"cqi_penalty\" in probs:\n",
    "            total_weight = probs[\"dropped_call\"] + probs[\"cqi_penalty\"]\n",
    "            if abs(total_weight - 1.0) > 1e-6:\n",
    "                logger.warning(f\"Weights for 'dropped_call' and 'cqi_penalty' sum to {total_weight}, which is not exactly 1.0. This might indicate an imbalance.\")\n",
    "\n",
    "    def _generate_documentation(self) -> str:\n",
    "        thresholds_doc = json.dumps(self.config['thresholds'], indent=2)\n",
    "        probabilities_doc = json.dumps(self.config['probabilities'], indent=2)\n",
    "        failure_types_doc = json.dumps([ft.value for ft in FailureType], indent=2)\n",
    "\n",
    "        return f\"\"\"## AEI Failure Simulation Configuration Documentation\n",
    "\n",
    "This document outlines the current configuration for the AEI Failure Simulation System.\n",
    "\n",
    "### Thresholds\n",
    "{thresholds_doc}\n",
    "\n",
    "### Probabilities\n",
    "{probabilities_doc}\n",
    "\n",
    "### Available Failure Types\n",
    "{failure_types_doc}\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _deep_merge(base: Dict, update: Dict) -> Dict:\n",
    "        for key, value in update.items():\n",
    "            if isinstance(value, dict) and key in base and isinstance(base[key], dict):\n",
    "                base[key] = AEIFailureConfigManager._deep_merge(base[key], value)\n",
    "            else:\n",
    "                base[key] = value\n",
    "        return base\n",
    "''')\n",
    "    \n",
    "    with open(CONFIG_FILE_PATH, 'w') as f:\n",
    "        f.write(failure_config_code)\n",
    "    logger.info(f\"✅ Module saved to {CONFIG_FILE_PATH}\")\n",
    "\n",
    "setup_module_environment()\n",
    "\n",
    "for module in list(sys.modules.keys()):\n",
    "    if module.startswith('aei.telecom.failure') or module == MODULE_NAME:\n",
    "        if module in sys.modules and hasattr(sys.modules[module], 'logger'):\n",
    "            mod_logger = sys.modules[module].logger\n",
    "            for handler in list(mod_logger.handlers):\n",
    "                mod_logger.removeHandler(handler)\n",
    "            mod_logger.propagate = True\n",
    "            mod_logger.setLevel(logging.NOTSET) \n",
    "        del sys.modules[module]\n",
    "        logger.debug(f\"Cleanup: Cleared '{module}' from sys.modules.\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(MODULE_NAME, CONFIG_FILE_PATH)\n",
    "if spec is None:\n",
    "    raise ImportError(f\"Could not load spec for module {MODULE_NAME}\")\n",
    "config_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[MODULE_NAME] = config_module\n",
    "spec.loader.exec_module(config_module)\n",
    "logger.info(f\"✅ Successfully loaded '{MODULE_NAME}'.\")\n",
    "\n",
    "if hasattr(config_module, 'AEIFailureConfigManager'):\n",
    "    initial_defaults_check = config_module.AEIFailureConfigManager._get_initial_defaults()\n",
    "    cqi_default_check_post_load = initial_defaults_check[\"thresholds\"][\"cqi\"]\n",
    "    logger.info(f\"AEIFailureConfigManager._get_initial_defaults()['thresholds']['cqi'] after module load: {cqi_default_check_post_load}\")\n",
    "    if cqi_default_check_post_load != 3:\n",
    "        logger.error(f\"CRITICAL: Default CQI in _get_initial_defaults() is not 3! It is {cqi_default_check_post_load}\")\n",
    "        raise AssertionError(f\"CRITICAL: Default CQI in _get_initial_defaults() is not 3! It is {cqi_default_check_post_load}\")\n",
    "    \n",
    "    dc_prob_default = initial_defaults_check[\"probabilities\"][\"dropped_call\"]\n",
    "    cqi_pen_default = initial_defaults_check[\"probabilities\"][\"cqi_penalty\"]\n",
    "    if abs(dc_prob_default + cqi_pen_default - 1.0) > 1e-6:\n",
    "        logger.error(f\"CRITICAL: Default dropped_call ({dc_prob_default}) and cqi_penalty ({cqi_pen_default}) do not sum to 1.0!\")\n",
    "        raise AssertionError(f\"CRITICAL: Default dropped_call and cqi_penalty do not sum to 1.0!\")\n",
    "else:\n",
    "    logger.error(\"AEIFailureConfigManager class not found in loaded module.\")\n",
    "\n",
    "try:\n",
    "    from aei.telecom.failure.config import AEIFailureConfigManager, FailureConfig, FailureType, ConfigurationError\n",
    "    logger.info(\"Successfully imported AEIFailureConfigManager and related classes for unit testing.\")\n",
    "\n",
    "    class TestAEIFailureConfigManager(unittest.TestCase):\n",
    "        @classmethod\n",
    "        def tearDownClass(cls):\n",
    "            cleanup_environment()\n",
    "            logger.info(\"--- ✅ All tests completed and environment cleaned. ---\")\n",
    "\n",
    "        def setUp(self):\n",
    "            self.test_module_logger = logging.getLogger(\"aei.telecom.failure.config\")\n",
    "            for handler in list(self.test_module_logger.handlers):\n",
    "                self.test_module_logger.removeHandler(handler)\n",
    "            self.test_module_logger.propagate = True\n",
    "            self.test_module_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "            root_logger = logging.getLogger()\n",
    "            for handler in list(root_logger.handlers):\n",
    "                root_logger.removeHandler(handler)\n",
    "            root_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "            if not root_logger.handlers: \n",
    "                handler = logging.StreamHandler(sys.stdout)\n",
    "                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "                handler.setFormatter(formatter)\n",
    "                root_logger.addHandler(handler)\n",
    "                logger.debug(\"Added a StreamHandler to the root logger for general test visibility.\")\n",
    "\n",
    "            self.default_config_data = AEIFailureConfigManager._get_initial_defaults()\n",
    "\n",
    "            self.temp_config_filepath = os.path.join(project_root, \"temp_test_config.json\")\n",
    "            with open(self.temp_config_filepath, 'w') as f:\n",
    "                json.dump(self.default_config_data, f)\n",
    "            logging.debug(f\"Created temporary config file: {self.temp_config_filepath}\")\n",
    "\n",
    "        def tearDown(self):\n",
    "            if os.path.exists(self.temp_config_filepath):\n",
    "                os.remove(self.temp_config_filepath)\n",
    "            logging.debug(f\"Removed temporary config file: {self.temp_config_filepath}\")\n",
    "\n",
    "            test_module_logger = logging.getLogger(\"aei.telecom.failure.config\")\n",
    "            for handler in list(test_module_logger.handlers):\n",
    "                test_module_logger.removeHandler(handler)\n",
    "            test_module_logger.propagate = True\n",
    "            test_module_logger.setLevel(logging.NOTSET)\n",
    "\n",
    "            root_logger = logging.getLogger()\n",
    "            for handler in list(root_logger.handlers):\n",
    "                root_logger.removeHandler(handler)\n",
    "            root_logger.setLevel(logging.WARNING)\n",
    "\n",
    "        def test_default_initialization(self):\n",
    "            manager = AEIFailureConfigManager()\n",
    "            self.assertIsInstance(manager, AEIFailureConfigManager)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"handover_user\"], self.default_config_data[\"thresholds\"][\"handover_user\"])\n",
    "            self.assertEqual(manager.config[\"probabilities\"][\"power_outage\"], self.default_config_data[\"probabilities\"][\"power_outage\"])\n",
    "            self.assertIn(\"POWER\", manager.config[\"failure_types\"])\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"cqi\"], 3)\n",
    "\n",
    "        def test_override_initialization(self):\n",
    "            override = {\n",
    "                \"thresholds\": {\"handover_user\": 100, \"sinr\": -5.0},\n",
    "                \"probabilities\": {\"power_outage\": 0.005},\n",
    "                \"failure_types\": [\"POWER_OUTAGE\", \"SOFTWARE\"]  # Changed from CUSTOM_FAILURE to SOFTWARE\n",
    "            }\n",
    "            manager = AEIFailureConfigManager(override)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"handover_user\"], 100)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"sinr\"], -5.0)\n",
    "            self.assertEqual(manager.config[\"probabilities\"][\"power_outage\"], 0.005)\n",
    "            self.assertEqual(manager.config[\"probabilities\"][\"dropped_call\"], 0.5)\n",
    "            self.assertEqual(sorted(manager.config[\"failure_types\"]), sorted([\"POWER_OUTAGE\", \"SOFTWARE\"]))\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"cqi\"], 3)\n",
    "\n",
    "        def test_create_failure_config_instance(self):\n",
    "            manager = AEIFailureConfigManager()\n",
    "            failure_cfg = manager.create_failure_config()\n",
    "            self.assertIsInstance(failure_cfg, FailureConfig)\n",
    "            self.assertEqual(failure_cfg.handover_user_threshold, 50)\n",
    "            self.assertEqual(failure_cfg.sinr_threshold, 0.0)\n",
    "            self.assertIsInstance(failure_cfg.failure_types, list)\n",
    "            self.assertEqual(failure_cfg.cqi_threshold, 3)\n",
    "\n",
    "        def test_failure_config_immutability(self):\n",
    "            manager = AEIFailureConfigManager()\n",
    "            failure_cfg = manager.create_failure_config()\n",
    "            with self.assertRaises(AttributeError):\n",
    "                failure_cfg.handover_user_threshold = 60\n",
    "\n",
    "        def test_from_json_success(self):\n",
    "            manager = AEIFailureConfigManager.from_json(self.temp_config_filepath)\n",
    "            self.assertIsInstance(manager, AEIFailureConfigManager)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"handover_user\"], 50)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"cqi\"], 3)\n",
    "\n",
    "        def test_from_json_file_not_found(self):\n",
    "            with self.assertRaisesRegex(FileNotFoundError, \"Configuration file not found\"):\n",
    "                AEIFailureConfigManager.from_json(\"non_existent_file_xyz.json\")\n",
    "\n",
    "        def test_from_json_invalid_json(self):\n",
    "            invalid_json_path = os.path.join(project_root, \"invalid_config_test.json\")\n",
    "            with open(invalid_json_path, 'w') as f:\n",
    "                f.write(\"{invalid_json\")\n",
    "            with self.assertRaisesRegex(ConfigurationError, \"Invalid JSON format\"):\n",
    "                AEIFailureConfigManager.from_json(invalid_json_path)\n",
    "            os.remove(invalid_json_path)\n",
    "\n",
    "        def test_from_dict_success(self):\n",
    "            config_dict = {\n",
    "                \"thresholds\": {\"handover_user\": 80},\n",
    "                \"probabilities\": {\"dropped_call\": 0.15, \"cqi_penalty\": 0.85}\n",
    "            }\n",
    "            manager = AEIFailureConfigManager.from_dict(config_dict)\n",
    "            self.assertIsInstance(manager, AEIFailureConfigManager)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"handover_user\"], 80)\n",
    "            self.assertEqual(manager.config[\"probabilities\"][\"dropped_call\"], 0.15)\n",
    "            self.assertEqual(manager.config[\"thresholds\"][\"cqi\"], 3)\n",
    "\n",
    "        def test_invalid_type_in_config(self):\n",
    "            invalid_config = {\"thresholds\": {\"cqi\": \"not_an_int\"}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"'thresholds\\.cqi' must be of type int\\. Got str\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config)\n",
    "\n",
    "        def test_unknown_key_in_config_top_level(self):\n",
    "            invalid_config = {\"unknown_top_level_key\": {}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"Unknown configuration keys found at '': unknown_top_level_key\\. Expected keys: .*\"):\n",
    "                AEIFailureConfigManager(invalid_config)\n",
    "                \n",
    "        def test_unknown_key_in_config_nested(self):\n",
    "            invalid_config_nested = {\"thresholds\": {\"cqi\": 5, \"extra_key\": 10}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"Unknown configuration keys found at 'thresholds\\.': extra_key\\. Expected keys: .*\"):\n",
    "                AEIFailureConfigManager(invalid_config_nested)\n",
    "\n",
    "        def test_invalid_structure_not_dict_sub_level(self):\n",
    "            invalid_config = {\"thresholds\": \"not_a_dict\"}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"'thresholds' must be a dictionary, not str\"):\n",
    "                AEIFailureConfigManager(invalid_config)\n",
    "                \n",
    "        def test_invalid_structure_not_dict_top_level(self):\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"Override config must be a dictionary or None\\. Got str\\.\"):\n",
    "                AEIFailureConfigManager(\"not_a_dict\")\n",
    "\n",
    "        def test_prob_out_of_range_high(self):\n",
    "            invalid_config = {\"probabilities\": {\"power_outage\": 1.1}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"'power_outage' probability \\(1\\.1\\) must be between 0 and 1\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config)\n",
    "\n",
    "        def test_prob_out_of_range_low(self):\n",
    "            invalid_config = {\"probabilities\": {\"dropped_call\": -0.1}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"'dropped_call' probability \\(-0\\.1\\) must be between 0 and 1\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config)\n",
    "\n",
    "        def test_handover_user_negative(self):\n",
    "            invalid_config = {\"thresholds\": {\"handover_user\": -10}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, \"Handover user threshold cannot be negative.\"):\n",
    "                AEIFailureConfigManager(invalid_config)\n",
    "\n",
    "        def test_rsrq_out_of_range(self):\n",
    "            invalid_config_high = {\"thresholds\": {\"rsrq\": 5.0}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"RSRQ threshold.*must be between -30 and 0 dB\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config_high)\n",
    "                \n",
    "            invalid_config_low = {\"thresholds\": {\"rsrq\": -40.0}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"RSRQ threshold.*must be between -30 and 0 dB\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config_low)\n",
    "\n",
    "        def test_cqi_out_of_range(self):\n",
    "            invalid_config_high = {\"thresholds\": {\"cqi\": 16}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"CQI threshold \\(16\\) must be between 1 and 15\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config_high)\n",
    "                \n",
    "            invalid_config_low = {\"thresholds\": {\"cqi\": 0}}\n",
    "            with self.assertRaisesRegex(ConfigurationError, r\"CQI threshold \\(0\\) must be between 1 and 15\\.\"):\n",
    "                AEIFailureConfigManager(invalid_config_low)\n",
    "\n",
    "        def test_sinr_threshold_warning(self):\n",
    "            log_capture_stream = StringIO()\n",
    "            handler = logging.StreamHandler(log_capture_stream)\n",
    "            formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            handler.setLevel(logging.WARNING) \n",
    "            \n",
    "            target_logger = logging.getLogger('aei.telecom.failure.config')\n",
    "            \n",
    "            for h in list(target_logger.handlers):\n",
    "                target_logger.removeHandler(h)\n",
    "\n",
    "            target_logger.addHandler(handler)\n",
    "            target_logger.setLevel(logging.DEBUG) \n",
    "            target_logger.propagate = False \n",
    "\n",
    "            try:\n",
    "                AEIFailureConfigManager({\"thresholds\": {\"sinr\": 10.0}})\n",
    "                log_output = log_capture_stream.getvalue()\n",
    "                self.assertIn(\"WARNING - SINR threshold (10.0 dB) is positive and quite high.\", log_output)\n",
    "                log_capture_stream.truncate(0) \n",
    "                log_capture_stream.seek(0)\n",
    "\n",
    "                AEIFailureConfigManager({\"thresholds\": {\"sinr\": -5.0}})\n",
    "                log_output_no_warning = log_capture_stream.getvalue()\n",
    "                self.assertNotIn(\"SINR threshold\", log_output_no_warning)\n",
    "                self.assertEqual(\"\", log_output_no_warning.strip()) \n",
    "            finally:\n",
    "                target_logger.removeHandler(handler) \n",
    "                target_logger.propagate = True \n",
    "                target_logger.setLevel(logging.NOTSET) \n",
    "\n",
    "        def test_dropped_cqi_weights_sum_warning(self):\n",
    "            log_capture_stream = StringIO()\n",
    "            handler = logging.StreamHandler(log_capture_stream)\n",
    "            formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            handler.setLevel(logging.WARNING)\n",
    "            \n",
    "            target_logger = logging.getLogger('aei.telecom.failure.config')\n",
    "\n",
    "            for h in list(target_logger.handlers):\n",
    "                target_logger.removeHandler(h)\n",
    "\n",
    "            target_logger.addHandler(handler)\n",
    "            target_logger.setLevel(logging.DEBUG)\n",
    "            target_logger.propagate = False \n",
    "\n",
    "            try:\n",
    "                AEIFailureConfigManager({\"probabilities\": {\"dropped_call\": 0.3, \"cqi_penalty\": 0.4}})\n",
    "                log_output = log_capture_stream.getvalue()\n",
    "                self.assertIn(\"WARNING - Weights for 'dropped_call' and 'cqi_penalty' sum to 0.7, which is not exactly 1.0.\", log_output)\n",
    "                log_capture_stream.truncate(0)\n",
    "                log_capture_stream.seek(0)\n",
    "\n",
    "                AEIFailureConfigManager({\"probabilities\": {\"dropped_call\": 0.65, \"cqi_penalty\": 0.3}})\n",
    "                log_output = log_capture_stream.getvalue()\n",
    "                self.assertIn(\"WARNING - Weights for 'dropped_call' and 'cqi_penalty' sum to 0.95, which is not exactly 1.0.\", log_output)\n",
    "                log_capture_stream.truncate(0)\n",
    "                log_capture_stream.seek(0)\n",
    "\n",
    "                AEIFailureConfigManager({\"probabilities\": {\"dropped_call\": 0.5, \"cqi_penalty\": 0.5}})\n",
    "                log_output_no_warning = log_capture_stream.getvalue()\n",
    "                self.assertEqual(\"\", log_output_no_warning.strip())\n",
    "                log_capture_stream.truncate(0)\n",
    "                log_capture_stream.seek(0)\n",
    "                \n",
    "                AEIFailureConfigManager({\"probabilities\": {\"dropped_call\": 0.4999999999, \"cqi_penalty\": 0.5000000001}})\n",
    "                log_output_no_warning = log_capture_stream.getvalue()\n",
    "                self.assertEqual(\"\", log_output_no_warning.strip())\n",
    "\n",
    "            finally:\n",
    "                target_logger.removeHandler(handler)\n",
    "                target_logger.propagate = True\n",
    "                target_logger.setLevel(logging.NOTSET)\n",
    "\n",
    "        def test_documentation_generation(self):\n",
    "            manager = AEIFailureConfigManager()\n",
    "            doc = manager.documentation\n",
    "            self.assertIsInstance(doc, str)\n",
    "            self.assertIn(\"AEI Failure Simulation Configuration Documentation\", doc)\n",
    "            self.assertIn(\"handover_user\", doc)\n",
    "            self.assertIn(str(manager.config[\"thresholds\"][\"handover_user\"]), doc)\n",
    "            self.assertIn(\"POWER\", doc)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "except ImportError as e:\n",
    "    logger.critical(f\"Error importing modules. Please ensure your 'aei/telecom/failure/config.py' file is correctly set up and accessible.\", exc_info=True)\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    logger.critical(f\"An unexpected critical error occurred during test setup or execution: {e}\", exc_info=True)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5578ad1",
   "metadata": {
    "papermill": {
     "duration": 0.011969,
     "end_time": "2025-07-21T17:38:46.912280",
     "exception": false,
     "start_time": "2025-07-21T17:38:46.900311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b814312",
   "metadata": {
    "papermill": {
     "duration": 0.011235,
     "end_time": "2025-07-21T17:38:46.935852",
     "exception": false,
     "start_time": "2025-07-21T17:38:46.924617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caed094",
   "metadata": {
    "papermill": {
     "duration": 0.011617,
     "end_time": "2025-07-21T17:38:46.959939",
     "exception": false,
     "start_time": "2025-07-21T17:38:46.948322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd # Needed for the test block below\n",
    "import numpy as np # Needed for the test block below\n",
    "\n",
    "# Create necessary directories and __init__.py files (ensure they exist)\n",
    "os.makedirs(\"/kaggle/working/aei/telecom/failure\", exist_ok=True)\n",
    "# Ensure top-level __init__.py files are present for package recognition\n",
    "open(\"/kaggle/working/aei/__init__.py\", \"a\").close() # Use 'a' to append if exists, or create\n",
    "open(\"/kaggle/working/aei/telecom/__init__.py\", \"a\").close()\n",
    "open(\"/kaggle/working/aei/telecom/failure/__init__.py\", \"a\").close()\n",
    "\n",
    "\n",
    "# The corrected code for failure_simulator.py\n",
    "corrected_failure_simulator_code = '''\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum, auto\n",
    "from functools import wraps\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FailureType(Enum):\n",
    "    DROPPED_CALL = auto()\n",
    "    HANDOVER_FAILURE = auto()\n",
    "    POWER_OUTAGE = auto()\n",
    "    # Adding generic types for compatibility with the main generator's config\n",
    "    POWER = auto()\n",
    "    BACKHAUL = auto()\n",
    "    SOFTWARE = auto()\n",
    "    HARDWARE = auto()\n",
    "\n",
    "@dataclass\n",
    "class FailureConfig:\n",
    "    \"\"\"Configuration for failure simulation parameters\"\"\"\n",
    "    handover_user_threshold: int = 50\n",
    "    power_outage_prob: float = 0.001\n",
    "    dropped_call_weight: float = 0.1\n",
    "    cqi_penalty_weight: float = 0.2\n",
    "    sinr_threshold: float = 0.0\n",
    "    rsrq_threshold: float = -15.0\n",
    "    cqi_threshold: int = 3\n",
    "    # Ensure these are also part of the config if used internally\n",
    "    failure_types: list = None # Will be set by __init__ if provided\n",
    "\n",
    "DEFAULT_FAILURE_CONFIG = FailureConfig(failure_types=['POWER', 'BACKHAUL', 'SOFTWARE', 'HARDWARE'])\n",
    "\n",
    "def timed_operation(func):\n",
    "    \"\"\"Decorator to log execution time of functions\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        logger.debug(f\"Operation {func.__name__} completed in {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class AEIFailureSimulator:\n",
    "    \"\"\"\n",
    "    Enterprise-grade failure simulation for telecom networks\n",
    "    \n",
    "    Features:\n",
    "    - Configurable failure thresholds\n",
    "    - Detailed logging\n",
    "    - Performance monitoring\n",
    "    - Type safety\n",
    "    - Validation\n",
    "    - Compatibility layer for existing data generation pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed: Optional[int] = None, failure_types: Optional[list] = None, config: Optional[FailureConfig] = None):\n",
    "        \"\"\"\n",
    "        Initializes the AEIFailureSimulator.\n",
    "\n",
    "        Args:\n",
    "            seed (Optional[int]): Seed for random number generation for reproducibility.\n",
    "            failure_types (Optional[list]): List of failure types (e.g., 'POWER', 'BACKHAUL').\n",
    "                                             If None, DEFAULT_FAILURE_CONFIG's types are used.\n",
    "            config (Optional[FailureConfig]): Configuration object for failure parameters.\n",
    "                                             If None, a default FailureConfig will be used.\n",
    "        \"\"\"\n",
    "        self.rng = np.random.RandomState(seed) # Initialize RNG with seed\n",
    "        self.config = config or DEFAULT_FAILURE_CONFIG\n",
    "        \n",
    "        # Override failure_types in config if provided directly\n",
    "        if failure_types is not None:\n",
    "            self.config.failure_types = failure_types\n",
    "        else:\n",
    "            # Ensure failure_types is always set, even if not provided in config or directly\n",
    "            self.config.failure_types = self.config.failure_types or DEFAULT_FAILURE_CONFIG.failure_types\n",
    "\n",
    "        self._validate_config()\n",
    "        logger.info(f\"AEIFailureSimulator initialized with seed: {seed}, failure_types: {self.config.failure_types}\")\n",
    "\n",
    "    def _validate_config(self):\n",
    "        \"\"\"Ensure configuration parameters are valid\"\"\"\n",
    "        if not 0 <= self.config.power_outage_prob <= 1:\n",
    "            raise ValueError(\"Power outage probability must be between 0 and 1\")\n",
    "        if self.config.handover_user_threshold < 0:\n",
    "            raise ValueError(\"User threshold cannot be negative\")\n",
    "        if not isinstance(self.config.failure_types, list) or not self.config.failure_types:\n",
    "            raise ValueError(\"failure_types must be a non-empty list.\")\n",
    "        logger.debug(\"FailureConfig validated successfully.\")\n",
    "\n",
    "    # This method acts as an adapter for compatibility with TelecomDataGenerator\n",
    "    def simulate_failures(self, df: pd.DataFrame, failure_prob: float = 0.05) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Simulates failures by introducing 'failure_type' based on a probability.\n",
    "        This method is an adapter to match the expected signature from TelecomDataGenerator.\n",
    "        It will call the more comprehensive 'simulate' method internally.\n",
    "        \"\"\"\n",
    "        if df.empty:\n",
    "            logger.warning(\"Received empty DataFrame for failure simulation.\")\n",
    "            return df.copy()\n",
    "\n",
    "        # The 'simulate' method in this class doesn't take failure_prob directly as a method argument\n",
    "        # but uses self.config.power_outage_prob.\n",
    "        # For compatibility, we can temporarily set the power_outage_prob if it differs,\n",
    "        # or just acknowledge that the main simulate method has its own internal logic.\n",
    "        # Given the existing structure, the 'simulate' method is more about adding specific failure columns\n",
    "        # based on thresholds, rather than a single 'failure_prob' for a generic 'failure_type'.\n",
    "        # We need to map the generic 'failure_prob' from TelecomDataGenerator to the specific failure types.\n",
    "\n",
    "        # Let's add a generic failure_type column first based on the overall probability,\n",
    "        # and then let the simulate method add specific failure indicators.\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Ensure 'failure_type' column is initialized as a string type before assigning categorical values\n",
    "        # This is the column TelecomDataGenerator expects to be populated with 'NONE', 'POWER', etc.\n",
    "        mask = self.rng.random(size=len(df_copy)) < failure_prob # Use self.rng for reproducibility\n",
    "        df_copy['failure_type'] = pd.Series('NONE', index=df_copy.index, dtype=object) \n",
    "        if mask.any():\n",
    "            df_copy.loc[mask, 'failure_type'] = self.rng.choice(self.config.failure_types, size=mask.sum()) # Use self.rng\n",
    "\n",
    "        # Now call the internal comprehensive simulation\n",
    "        # The 'simulate' method will add 'Dropped_Calls', 'Handover_Failures', 'Power_Outage', 'Request_Failure_Rate'\n",
    "        # These are internal detailed failure indicators. The 'failure_type' above is the high-level category.\n",
    "        df_final = self.simulate(df_copy)\n",
    "        \n",
    "        return df_final\n",
    "\n",
    "\n",
    "    @timed_operation\n",
    "    def simulate(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Simulate network failures on telecom data. This is the comprehensive method.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing network metrics (RSRP, RSRQ, SINR, CQI, device_count).\n",
    "                Note: \"User Count\" is expected to be \"device_count\" from TelecomDataGenerator.\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with added failure columns:\n",
    "            - Dropped_Calls (binary)\n",
    "            - Handover_Failures (binary)\n",
    "            - Power_Outage (binary)\n",
    "            - Request_Failure_Rate (float)\n",
    "        \"\"\"\n",
    "        self._validate_input(df)\n",
    "        \n",
    "        try:\n",
    "            df_processed = df.copy()\n",
    "            df_processed[\"Dropped_Calls\"] = self._calculate_dropped_calls(df_processed)\n",
    "            df_processed[\"Handover_Failures\"] = self._calculate_handover_failures(df_processed)\n",
    "            df_processed[\"Power_Outage\"] = self._simulate_power_outages(len(df_processed)) # Use self.rng internally\n",
    "            df_processed[\"Request_Failure_Rate\"] = self._calculate_failure_rate(df_processed)\n",
    "            \n",
    "            logger.info(f\"Simulated detailed failures on {len(df_processed)} records\")\n",
    "            self._log_failure_stats(df_processed)\n",
    "            \n",
    "            return df_processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Comprehensive failure simulation error: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "            \n",
    "    def _validate_input(self, df: pd.DataFrame):\n",
    "        \"\"\"Validate input DataFrame structure\"\"\"\n",
    "        # Adjusted to expect 'device_count' instead of 'User Count'\n",
    "        required_columns = {\"RSRP\", \"RSRQ\", \"SINR\", \"CQI\", \"device_count\"}\n",
    "        missing = required_columns - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns for failure simulation: {missing}\")\n",
    "        logger.debug(\"Input DataFrame validated for failure simulation.\")\n",
    "            \n",
    "    def _calculate_dropped_calls(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate dropped calls based on signal quality\"\"\"\n",
    "        # Ensure columns are numeric, coercing errors to handle potential NaNs\n",
    "        sinr = pd.to_numeric(df[\"SINR\"], errors='coerce').fillna(0)\n",
    "        rsrq = pd.to_numeric(df[\"RSRQ\"], errors='coerce').fillna(0)\n",
    "        return ((sinr < self.config.sinr_threshold) | \n",
    "                (rsrq < self.config.rsrq_threshold)).astype(int)\n",
    "    \n",
    "    def _calculate_handover_failures(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate handover failures based on load and quality\"\"\"\n",
    "        # Adjusted to use 'device_count'\n",
    "        cqi = pd.to_numeric(df[\"CQI\"], errors='coerce').fillna(0)\n",
    "        device_count = pd.to_numeric(df[\"device_count\"], errors='coerce').fillna(0)\n",
    "        return ((cqi < self.config.cqi_threshold) & \n",
    "                (device_count > self.config.handover_user_threshold)).astype(int)\n",
    "    \n",
    "    def _simulate_power_outages(self, size: int) -> pd.Series:\n",
    "        \"\"\"Simulate random power outages\"\"\"\n",
    "        return (self.rng.rand(size) < self.config.power_outage_prob).astype(int) # Use self.rng\n",
    "    \n",
    "    def _calculate_failure_rate(self, df: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate composite failure rate metric\"\"\"\n",
    "        # Ensure CQI is numeric for calculation\n",
    "        cqi = pd.to_numeric(df[\"CQI\"], errors='coerce').fillna(0)\n",
    "        return np.clip(\n",
    "            (self.config.dropped_call_weight * df[\"Dropped_Calls\"] +\n",
    "             self.config.cqi_penalty_weight * (100 - cqi)), # Use the numeric cqi\n",
    "            0, 100\n",
    "        )\n",
    "    \n",
    "    def _log_failure_stats(self, df: pd.DataFrame):\n",
    "        \"\"\"Log statistics about simulated failures\"\"\"\n",
    "        stats = {\n",
    "            FailureType.DROPPED_CALL: df[\"Dropped_Calls\"].sum(),\n",
    "            FailureType.HANDOVER_FAILURE: df[\"Handover_Failures\"].sum(),\n",
    "            FailureType.POWER_OUTAGE: df[\"Power_Outage\"].sum()\n",
    "        }\n",
    "        \n",
    "        for failure_type, count in stats.items():\n",
    "            if len(df) > 0:\n",
    "                rate = count / len(df) * 100\n",
    "            else:\n",
    "                rate = 0.0 # Handle empty DataFrame case\n",
    "            logger.info(f\"{failure_type.name}: {count} occurrences ({rate:.2f}%)\")\n",
    "\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open(\"/kaggle/working/aei/telecom/failure/failure_simulator.py\", \"w\") as f:\n",
    "    f.write(corrected_failure_simulator_code)\n",
    "\n",
    "# Add /kaggle/working to sys.path so Python can find the aei package\n",
    "if \"/kaggle/working\" not in sys.path:\n",
    "    sys.path.append(\"/kaggle/working\")\n",
    "\n",
    "# Now you can import and test\n",
    "try:\n",
    "    from aei.telecom.failure.failure_simulator import AEIFailureSimulator, FailureConfig\n",
    "    print(\"Successfully imported AEIFailureSimulator from the corrected file!\")\n",
    "\n",
    "    # Example test DataFrame (ensure it has required columns)\n",
    "    test_df = pd.DataFrame({\n",
    "        'RSRP': np.random.uniform(-100, -50, 10),\n",
    "        'RSRQ': np.random.uniform(-20, -5, 10),\n",
    "        'SINR': np.random.uniform(-5, 25, 10),\n",
    "        'CQI': np.random.randint(1, 16, 10),\n",
    "        'device_count': np.random.randint(10, 100, 10)\n",
    "    })\n",
    "\n",
    "    # Test with seed and custom failure types\n",
    "    simulator = AEIFailureSimulator(seed=42, failure_types=['TYPE_A', 'TYPE_B'])\n",
    "    result_df = simulator.simulate_failures(test_df, failure_prob=0.3) # Using the adapter method\n",
    "\n",
    "    print(\"\\nSample generated failures:\")\n",
    "    print(result_df[['RSRP', 'SINR', 'CQI', 'device_count', 'failure_type', \n",
    "                     'Dropped_Calls', 'Handover_Failures', 'Power_Outage', 'Request_Failure_Rate']].head())\n",
    "    print(\"\\nFailure Type Distribution (from simulate_failures):\")\n",
    "    print(result_df['failure_type'].value_counts())\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing AEIFailureSimulator: {e}. Make sure the file is saved correctly and __init__.py files are present.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during testing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f2b94",
   "metadata": {
    "papermill": {
     "duration": 0.010638,
     "end_time": "2025-07-21T17:38:46.983287",
     "exception": false,
     "start_time": "2025-07-21T17:38:46.972649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import textwrap # Import textwrap for clean string indentation\n",
    "import logging\n",
    "\n",
    "# Set up logging for the test environment to avoid clutter from the simulator's INFO logs\n",
    "logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ensure the aei package path is in sys.path\n",
    "# This block should ideally be run once before any imports from 'aei'\n",
    "# but is included here for completeness of the self-contained test script.\n",
    "if \"/kaggle/working\" not in sys.path:\n",
    "    sys.path.append(\"/kaggle/working\")\n",
    "\n",
    "# Create necessary directories and __init__.py files for the AEI package structure\n",
    "# This ensures the 'aei' package is discoverable by Python's import system\n",
    "os.makedirs(\"/kaggle/working/aei/telecom/signal\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/aei/telecom/failure\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/aei/telecom/outage\", exist_ok=True)\n",
    "\n",
    "open(\"/kaggle/working/aei/__init__.py\", \"w\").close()\n",
    "open(\"/kaggle/working/aei/telecom/__init__.py\", \"w\").close()\n",
    "open(\"/kaggle/working/aei/telecom/signal/__init__.py\", \"w\").close()\n",
    "open(\"/kaggle/working/aei/telecom/failure/__init__.py\", \"w\").close()\n",
    "open(\"/kaggle/working/aei/telecom/outage/__init__.py\", \"w\").close()\n",
    "\n",
    "# --- Start of corrected aei/telecom/failure/failure_simulator.py content ---\n",
    "# This part ensures the simulator itself is correctly defined before tests run\n",
    "failure_simulator_code = textwrap.dedent('''\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    from typing import Dict, Any, Optional\n",
    "    from dataclasses import dataclass, field\n",
    "    from enum import Enum, auto\n",
    "    from functools import wraps\n",
    "    from time import perf_counter\n",
    "    import pandas as pd\n",
    "\n",
    "    # Setup logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    class AEIFailureType(Enum):\n",
    "        DROPPED_CALL = auto()\n",
    "        HANDOVER_FAILURE = auto()\n",
    "        POWER_OUTAGE = auto()\n",
    "        POWER = auto()\n",
    "        BACKHAUL = auto()\n",
    "        SOFTWARE = auto()\n",
    "        HARDWARE = auto()\n",
    "\n",
    "    @dataclass\n",
    "    class AEIFailureConfig:\n",
    "        \"\"\"Configuration for failure simulation parameters\"\"\"\n",
    "        handover_user_threshold: int = 50\n",
    "        power_outage_prob: float = 0.001\n",
    "        dropped_call_weight: float = 0.1\n",
    "        cqi_penalty_weight: float = 0.2\n",
    "        sinr_threshold: float = 0.0\n",
    "        rsrq_threshold: float = -15.0\n",
    "        cqi_threshold: int = 3\n",
    "        failure_types: list = field(default_factory=lambda: ['POWER', 'BACKHAUL', 'SOFTWARE', 'HARDWARE']) # Using default_factory\n",
    "\n",
    "        def __post_init__(self):\n",
    "            \"\"\"Validate configuration parameters after initialization.\"\"\"\n",
    "            if not 0 <= self.power_outage_prob <= 1:\n",
    "                raise ValueError(\"Power outage probability must be between 0 and 1\")\n",
    "            if self.handover_user_threshold < 0:\n",
    "                raise ValueError(\"User threshold cannot be negative\")\n",
    "            if not isinstance(self.failure_types, list) or not self.failure_types:\n",
    "                raise ValueError(\"failure_types must be a non-empty list.\")\n",
    "            logger.debug(\"AEIFailureConfig validated successfully.\")\n",
    "\n",
    "\n",
    "    AEIDEFAULT_FAILURE_CONFIG = AEIFailureConfig() # Now just instantiate directly, validation in __post_init__\n",
    "\n",
    "    def timed_operation(func):\n",
    "        \"\"\"Decorator to log execution time of functions\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = perf_counter()\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = perf_counter()\n",
    "            logger.debug(f\"Operation {func.__name__} completed in {end_time - start_time:.4f} seconds\")\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    class AEIFailureSimulator:\n",
    "        \"\"\"\n",
    "        Enterprise-grade failure simulation for telecom networks\n",
    "        \n",
    "        Features:\n",
    "        - Configurable failure thresholds\n",
    "        - Detailed logging\n",
    "        - Performance monitoring\n",
    "        - Type safety\n",
    "        - Validation\n",
    "        - Compatibility layer for existing data generation pipelines.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self, seed: Optional[int] = None, failure_types: Optional[list] = None, config: Optional[AEIFailureConfig] = None):\n",
    "            \"\"\"\n",
    "            Initializes the AEIFailureSimulator.\n",
    "\n",
    "            Args:\n",
    "                seed (Optional[int]): Seed for random number generation for reproducibility.\n",
    "                failure_types (Optional[list]): List of failure types (e.g., 'POWER', 'BACKHAUL').\n",
    "                                                 If None, AEIDEFAULT_FAILURE_CONFIG's types are used.\n",
    "                config (Optional[AEIFailureConfig]): Configuration object for failure parameters.\n",
    "                                                 If None, a default AEIFailureConfig will be used.\n",
    "            \"\"\"\n",
    "            self.rng = np.random.RandomState(seed) # Initialize RNG with seed\n",
    "            \n",
    "            if config is None:\n",
    "                # If no config is provided, create one and potentially override failure_types\n",
    "                if failure_types is not None:\n",
    "                    self.config = AEIFailureConfig(failure_types=failure_types)\n",
    "                else:\n",
    "                    self.config = AEIDEFAULT_FAILURE_CONFIG\n",
    "            else:\n",
    "                self.config = config\n",
    "                # If a config is provided, and failure_types is ALSO provided, override config's failure_types\n",
    "                if failure_types is not None:\n",
    "                    self.config.failure_types = failure_types # This directly modifies the provided config object\n",
    "\n",
    "            logger.info(f\"AEIFailureSimulator initialized with seed: {seed}, failure_types: {self.config.failure_types}\")\n",
    "\n",
    "        # Removed _validate_config as validation is now in AEIFailureConfig.__post_init__\n",
    "\n",
    "        def simulate_failures(self, df: pd.DataFrame, failure_prob: float = 0.05) -> pd.DataFrame:\n",
    "            \"\"\"\n",
    "            Simulates failures by introducing 'failure_type' based on a probability.\n",
    "            This method is an adapter to match the expected signature from TelecomDataGenerator.\n",
    "            It will call the more comprehensive 'simulate' method internally.\n",
    "            \"\"\"\n",
    "            if df.empty:\n",
    "                logger.warning(\"Received empty DataFrame for failure simulation.\")\n",
    "                empty_result = self.simulate(df.copy()) # Call simulate to get expected columns\n",
    "                empty_result['failure_type'] = pd.Series(dtype=object) # Add the column as empty\n",
    "                return empty_result\n",
    "\n",
    "            df_copy = df.copy()\n",
    "            \n",
    "            mask = self.rng.random(size=len(df_copy)) < failure_prob\n",
    "            df_copy['failure_type'] = pd.Series('NONE', index=df_copy.index, dtype=object) \n",
    "            if mask.any():\n",
    "                df_copy.loc[mask, 'failure_type'] = self.rng.choice(self.config.failure_types, size=mask.sum())\n",
    "\n",
    "            df_final = self.simulate(df_copy)\n",
    "            \n",
    "            return df_final\n",
    "\n",
    "\n",
    "        @timed_operation\n",
    "        def simulate(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "            \"\"\"\n",
    "            Simulate network failures on telecom data. This is the comprehensive method.\n",
    "            \n",
    "            Args:\n",
    "                df: DataFrame containing network metrics (RSRP, RSRQ, SINR, CQI, device_count).\n",
    "                \n",
    "            Returns:\n",
    "                DataFrame with added failure columns:\n",
    "                - Dropped_Calls (binary)\n",
    "                - Handover_Failures (binary)\n",
    "                - Power_Outage (binary)\n",
    "                - Request_Failure_Rate (float)\n",
    "                (Note: 'failure_type' is added by simulate_failures, not directly by this method)\n",
    "            \"\"\"\n",
    "            self._validate_input(df) # Input DataFrame structure validation\n",
    "            \n",
    "            try:\n",
    "                df_processed = df.copy()\n",
    "                df_processed[\"Dropped_Calls\"] = self._calculate_dropped_calls(df_processed)\n",
    "                df_processed[\"Handover_Failures\"] = self._calculate_handover_failures(df_processed)\n",
    "                df_processed[\"Power_Outage\"] = self._simulate_power_outages(len(df_processed))\n",
    "                df_processed[\"Request_Failure_Rate\"] = self._calculate_failure_rate(df_processed)\n",
    "                \n",
    "                logger.info(f\"Simulated detailed failures on {len(df_processed)} records\")\n",
    "                self._log_failure_stats(df_processed)\n",
    "                \n",
    "                return df_processed\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Comprehensive failure simulation error: {str(e)}\", exc_info=True)\n",
    "                raise\n",
    "                \n",
    "        def _validate_input(self, df: pd.DataFrame):\n",
    "            \"\"\"Validate input DataFrame structure\"\"\"\n",
    "            required_columns = {\"RSRP\", \"RSRQ\", \"SINR\", \"CQI\", \"device_count\"}\n",
    "            missing = required_columns - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing required columns for failure simulation: {missing}\")\n",
    "            logger.debug(\"Input DataFrame validated for failure simulation.\")\n",
    "                \n",
    "        def _calculate_dropped_calls(self, df: pd.DataFrame) -> pd.Series:\n",
    "            \"\"\"Calculate dropped calls based on signal quality\"\"\"\n",
    "            sinr = pd.to_numeric(df[\"SINR\"], errors='coerce').fillna(0)\n",
    "            rsrq = pd.to_numeric(df[\"RSRQ\"], errors='coerce').fillna(0)\n",
    "            return ((sinr < self.config.sinr_threshold) | \n",
    "                    (rsrq < self.config.rsrq_threshold)).astype(int)\n",
    "        \n",
    "        def _calculate_handover_failures(self, df: pd.DataFrame) -> pd.Series:\n",
    "            \"\"\"Calculate handover failures based on load and quality\"\"\"\n",
    "            cqi = pd.to_numeric(df[\"CQI\"], errors='coerce').fillna(0)\n",
    "            device_count = pd.to_numeric(df[\"device_count\"], errors='coerce').fillna(0)\n",
    "            return ((cqi < self.config.cqi_threshold) & \n",
    "                    (device_count > self.config.handover_user_threshold)).astype(int)\n",
    "        \n",
    "        def _simulate_power_outages(self, size: int) -> pd.Series:\n",
    "            \"\"\"Simulate random power outages\"\"\"\n",
    "            return (self.rng.rand(size) < self.config.power_outage_prob).astype(int)\n",
    "        \n",
    "        def _calculate_failure_rate(self, df: pd.DataFrame) -> pd.Series:\n",
    "            \"\"\"Calculate composite failure rate metric\"\"\"\n",
    "            cqi = pd.to_numeric(df[\"CQI\"], errors='coerce').fillna(0)\n",
    "            return np.clip(\n",
    "                (self.config.dropped_call_weight * df[\"Dropped_Calls\"] +\n",
    "                 self.config.cqi_penalty_weight * (100 - cqi)),\n",
    "                0, 100\n",
    "            )\n",
    "        \n",
    "        def _log_failure_stats(self, df: pd.DataFrame):\n",
    "            \"\"\"Log statistics about simulated failures\"\"\"\n",
    "            stats = {\n",
    "                AEIFailureType.DROPPED_CALL: df[\"Dropped_Calls\"].sum(),\n",
    "                AEIFailureType.HANDOVER_FAILURE: df[\"Handover_Failures\"].sum(),\n",
    "                AEIFailureType.POWER_OUTAGE: df[\"Power_Outage\"].sum()\n",
    "            }\n",
    "            \n",
    "            for failure_type, count in stats.items():\n",
    "                if len(df) > 0:\n",
    "                    rate = count / len(df) * 100\n",
    "                else:\n",
    "                    rate = 0.0\n",
    "                logger.info(f\"{failure_type.name}: {count} occurrences ({rate:.2f}%)\")\n",
    "''')\n",
    "\n",
    "# Save the corrected failure_simulator.py content\n",
    "with open(\"/kaggle/working/aei/telecom/failure/failure_simulator.py\", \"w\") as f:\n",
    "    f.write(failure_simulator_code)\n",
    "\n",
    "# --- End of aei/telecom/failure/failure_simulator.py content ---\n",
    "\n",
    "\n",
    "# --- Start of test_failure_simulator.py content ---\n",
    "test_code = textwrap.dedent('''\n",
    "    import pytest\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    from aei.telecom.failure.failure_simulator import AEIFailureSimulator, AEIFailureConfig, AEIFailureType, AEIDEFAULT_FAILURE_CONFIG\n",
    "\n",
    "    # Configure logging to suppress INFO messages during tests,\n",
    "    # as pytest handles test reporting.\n",
    "    logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    @pytest.fixture\n",
    "    def sample_df() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Provides a sample DataFrame for testing the Simulator.\n",
    "        \"\"\"\n",
    "        return pd.DataFrame({\n",
    "            \"RSRP\": np.random.uniform(-100, -50, 100),\n",
    "            \"RSRQ\": np.random.uniform(-20, -5, 100),\n",
    "            \"SINR\": np.random.uniform(-5, 20, 100),\n",
    "            \"CQI\": np.random.randint(1, 16, 100),\n",
    "            \"device_count\": np.random.randint(10, 100, 100)\n",
    "        })\n",
    "\n",
    "    def test_basic_simulation(sample_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Tests the basic simulation functionality with default configuration.\n",
    "        Ensures all expected columns are added and their types are correct.\n",
    "        This test calls the 'simulate' method, which does NOT add 'failure_type'.\n",
    "        \"\"\"\n",
    "        simulator = AEIFailureSimulator(seed=42)\n",
    "        result_df = simulator.simulate(sample_df.copy())\n",
    "\n",
    "        expected_columns = [\"Dropped_Calls\", \"Handover_Failures\", \"Power_Outage\", \"Request_Failure_Rate\"]\n",
    "        for col in expected_columns:\n",
    "            assert col in result_df.columns, f\"Column '{col}' missing from result DataFrame.\"\n",
    "\n",
    "        assert result_df[\"Dropped_Calls\"].dtype == int, \"'Dropped_Calls' column not integer type.\"\n",
    "        assert result_df[\"Handover_Failures\"].dtype == int, \"'Handover_Failures' column not integer type.\"\n",
    "        assert result_df[\"Power_Outage\"].dtype == int, \"'Power_Outage' column not integer type.\"\n",
    "        assert np.issubdtype(result_df[\"Request_Failure_Rate\"].dtype, np.number), \"'Request_Failure_Rate' column not numeric type.\"\n",
    "\n",
    "        assert len(result_df) == len(sample_df), \"Result DataFrame row count mismatch.\"\n",
    "        assert \"failure_type\" not in result_df.columns, \"'failure_type' column should NOT be present from direct simulate() call.\"\n",
    "\n",
    "    def test_custom_config_simulation(sample_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Tests simulation with a custom AEIFailureConfig.\n",
    "        Ensures the simulator accepts and uses the custom configuration.\n",
    "        This test calls the 'simulate' method, which does NOT add 'failure_type'.\n",
    "        \"\"\"\n",
    "        custom_config = AEIFailureConfig(\n",
    "            handover_user_threshold=20,\n",
    "            power_outage_prob=0.1,\n",
    "            dropped_call_weight=0.5,\n",
    "            cqi_penalty_weight=0.8,\n",
    "            sinr_threshold=5.0,\n",
    "            rsrq_threshold=-10.0,\n",
    "            cqi_threshold=5,\n",
    "            failure_types=['CUSTOM_A', 'CUSTOM_B']\n",
    "        )\n",
    "        simulator_custom = AEIFailureSimulator(config=custom_config)\n",
    "        result_df_custom = simulator_custom.simulate(sample_df.copy())\n",
    "\n",
    "        assert \"Dropped_Calls\" in result_df_custom.columns, \"Custom config simulation failed: 'Dropped_Calls' column missing.\"\n",
    "        assert len(result_df_custom) == len(sample_df), \"Custom config simulation failed: Result DataFrame row count mismatch.\"\n",
    "        assert \"failure_type\" not in result_df_custom.columns, \"'failure_type' column should NOT be present from direct simulate() call.\"\n",
    "\n",
    "\n",
    "    def test_input_validation_missing_columns():\n",
    "        \"\"\"\n",
    "        Tests that a ValueError is raised when required input columns are missing.\n",
    "        \"\"\"\n",
    "        df_invalid = pd.DataFrame({\"RSRP\": [1], \"CQI\": [2], \"SINR\": [3], \"RSRQ\": [4]})\n",
    "        simulator = AEIFailureSimulator()\n",
    "        with pytest.raises(ValueError, match=\"Missing required columns\"):\n",
    "            simulator.simulate(df_invalid)\n",
    "\n",
    "    def test_config_validation_invalid_power_outage_prob():\n",
    "        \"\"\"\n",
    "        Tests that a ValueError is raised for an invalid power_outage_prob in configuration.\n",
    "        \"\"\"\n",
    "        with pytest.raises(ValueError, match=\"Power outage probability must be between 0 and 1\"):\n",
    "            AEIFailureConfig(power_outage_prob=1.5)\n",
    "        with pytest.raises(ValueError, match=\"Power outage probability must be between 0 and 1\"):\n",
    "            AEIFailureConfig(power_outage_prob=-0.1)\n",
    "\n",
    "    def test_config_validation_negative_user_threshold():\n",
    "        \"\"\"\n",
    "        Tests that a ValueError is raised for a negative handover_user_threshold in configuration.\n",
    "        \"\"\"\n",
    "        with pytest.raises(ValueError, match=\"User threshold cannot be negative\"):\n",
    "            AEIFailureConfig(handover_user_threshold=-10)\n",
    "\n",
    "    def test_config_validation_empty_failure_types():\n",
    "        \"\"\"\n",
    "        Tests that a ValueError is raised for an empty or invalid failure_types list in configuration.\n",
    "        \"\"\"\n",
    "        with pytest.raises(ValueError, match=\"failure_types must be a non-empty list.\"):\n",
    "            AEIFailureConfig(failure_types=[])\n",
    "        # The default_factory handles None if not explicitly passed, so this might not raise if AEIFailureConfig() is default\n",
    "        with pytest.raises(ValueError, match=\"failure_types must be a non-empty list.\"):\n",
    "             # This explicitly sets failure_types to None\n",
    "            AEIFailureConfig(failure_types=None)\n",
    "        with pytest.raises(ValueError, match=\"failure_types must be a non-empty list.\"):\n",
    "            AEIFailureConfig(failure_types=\"not a list\")\n",
    "\n",
    "\n",
    "    def test_dropped_call_condition():\n",
    "        \"\"\"\n",
    "        Tests that dropped calls are correctly identified based on SINR and RSRQ thresholds.\n",
    "        \"\"\"\n",
    "        # Scenario 1: SINR too low -> Dropped Call\n",
    "        df_sinr_low = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [-1.0], \"CQI\": [10], \"device_count\": [30]\n",
    "        })\n",
    "        sim_sinr = AEIFailureSimulator(config=AEIFailureConfig(sinr_threshold=0.0, rsrq_threshold=-15.0))\n",
    "        res_sinr = sim_sinr.simulate(df_sinr_low)\n",
    "        assert res_sinr[\"Dropped_Calls\"].iloc[0] == 1, \"Dropped Call not detected for low SINR.\"\n",
    "\n",
    "        # Scenario 2: RSRQ too low -> Dropped Call\n",
    "        df_rsrq_low = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-18], \"SINR\": [5.0], \"CQI\": [10], \"device_count\": [30]\n",
    "        })\n",
    "        sim_rsrq = AEIFailureSimulator(config=AEIFailureConfig(sinr_threshold=0.0, rsrq_threshold=-15.0))\n",
    "        res_rsrq = sim_rsrq.simulate(df_rsrq_low)\n",
    "        assert res_rsrq[\"Dropped_Calls\"].iloc[0] == 1, \"Dropped Call not detected for low RSRQ.\"\n",
    "\n",
    "        # Scenario 3: Both OK -> No Dropped Call\n",
    "        df_all_ok = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [5.0], \"CQI\": [10], \"device_count\": [30]\n",
    "        })\n",
    "        sim_ok = AEIFailureSimulator(config=AEIFailureConfig(sinr_threshold=0.0, rsrq_threshold=-15.0))\n",
    "        res_ok = sim_ok.simulate(df_all_ok)\n",
    "        assert res_ok[\"Dropped_Calls\"].iloc[0] == 0, \"Dropped Call incorrectly detected when conditions are met.\"\n",
    "\n",
    "\n",
    "    def test_handover_failure_condition():\n",
    "        \"\"\"\n",
    "        Tests that handover failures are correctly identified based on CQI and device_count thresholds.\n",
    "        \"\"\"\n",
    "        # Scenario 1: CQI low AND device_count high -> Handover Failure\n",
    "        df_fail = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [10.0], \"CQI\": [2], \"device_count\": [60]\n",
    "        })\n",
    "        sim_fail = AEIFailureSimulator(config=AEIFailureConfig(cqi_threshold=3, handover_user_threshold=50))\n",
    "        res_fail = sim_fail.simulate(df_fail)\n",
    "        assert res_fail[\"Handover_Failures\"].iloc[0] == 1, \"Handover Failure not detected.\"\n",
    "\n",
    "        # Scenario 2: CQI low BUT device_count low -> No Handover Failure\n",
    "        df_cqi_low_device_low = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [10.0], \"CQI\": [2], \"device_count\": [40]\n",
    "        })\n",
    "        sim_no_fail1 = AEIFailureSimulator(config=AEIFailureConfig(cqi_threshold=3, handover_user_threshold=50))\n",
    "        res_no_fail1 = sim_no_fail1.simulate(df_cqi_low_device_low)\n",
    "        assert res_no_fail1[\"Handover_Failures\"].iloc[0] == 0, \"Handover Failure incorrectly detected (device count low).\"\n",
    "\n",
    "        # Scenario 3: CQI high AND device_count high -> No Handover Failure\n",
    "        df_cqi_high_device_high = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [10.0], \"CQI\": [5], \"device_count\": [60]\n",
    "        })\n",
    "        sim_no_fail2 = AEIFailureSimulator(config=AEIFailureConfig(cqi_threshold=3, handover_user_threshold=50))\n",
    "        res_no_fail2 = sim_no_fail2.simulate(df_cqi_high_device_high)\n",
    "        assert res_no_fail2[\"Handover_Failures\"].iloc[0] == 0, \"Handover Failure incorrectly detected (CQI high).\"\n",
    "\n",
    "    def test_power_outage_simulation():\n",
    "        \"\"\"\n",
    "        Tests that power outages are simulated correctly based on probability.\n",
    "        \"\"\"\n",
    "        simulator = AEIFailureSimulator(seed=10, config=AEIFailureConfig(power_outage_prob=0.5))\n",
    "        df_test = pd.DataFrame({\"RSRP\": [1]*10, \"RSRQ\": [1]*10, \"SINR\": [1]*10, \"CQI\": [1]*10, \"device_count\": [1]*10})\n",
    "        result_df = simulator.simulate(df_test)\n",
    "        \n",
    "        assert result_df[\"Power_Outage\"].dtype == int\n",
    "        assert result_df[\"Power_Outage\"].isin([0, 1]).all()\n",
    "        # For prob 0.5, with seed 10, rng.rand(10) will produce 6 values < 0.5\n",
    "        assert result_df[\"Power_Outage\"].sum() == 6 # CORRECTED: Changed expected sum from 7 to 6\n",
    "\n",
    "\n",
    "    def test_failure_rate_calculation():\n",
    "        \"\"\"\n",
    "        Tests the composite failure rate calculation, ensuring it's within bounds.\n",
    "        \"\"\"\n",
    "        df_rate_calc = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [-1.0], \"CQI\": [50], \"device_count\": [30]\n",
    "        })\n",
    "        \n",
    "        config_rate = AEIFailureConfig(dropped_call_weight=0.1, cqi_penalty_weight=0.2, sinr_threshold=0.0)\n",
    "        simulator_rate = AEIFailureSimulator(config=config_rate)\n",
    "        \n",
    "        result_df = simulator_rate.simulate(df_rate_calc)\n",
    "        \n",
    "        expected_rate = (config_rate.dropped_call_weight * 1 +\n",
    "                         config_rate.cqi_penalty_weight * (100 - 50))\n",
    "        \n",
    "        assert np.isclose(result_df[\"Request_Failure_Rate\"].iloc[0], expected_rate), \\\n",
    "            f\"Failure rate calculation incorrect. Expected {expected_rate}, got {result_df['Request_Failure_Rate'].iloc[0]}\"\n",
    "        \n",
    "        config_clip = AEIFailureConfig(dropped_call_weight=0.1, cqi_penalty_weight=1.5, sinr_threshold=0.0)\n",
    "        simulator_clip = AEIFailureSimulator(config=config_clip)\n",
    "\n",
    "        df_clipped_input = pd.DataFrame({\n",
    "            \"RSRP\": [-70], \"RSRQ\": [-10], \"SINR\": [1.0], \"CQI\": [0], \"device_count\": [30]\n",
    "        })\n",
    "        \n",
    "        result_clipped = simulator_clip.simulate(df_clipped_input)\n",
    "        assert result_clipped[\"Request_Failure_Rate\"].iloc[0] == 100, \"Failure rate not clipped to 100.\"\n",
    "\n",
    "    def test_simulate_failures_adapter_method_empty_df():\n",
    "        \"\"\"\n",
    "        Tests the simulate_failures adapter method with an empty DataFrame,\n",
    "        ensuring it returns an empty DataFrame with expected columns.\n",
    "        \"\"\"\n",
    "        simulator = AEIFailureSimulator(seed=1)\n",
    "        empty_df = pd.DataFrame(columns=[\"RSRP\", \"RSRQ\", \"SINR\", \"CQI\", \"device_count\"])\n",
    "        \n",
    "        result = simulator.simulate_failures(empty_df, failure_prob=0.5)\n",
    "        \n",
    "        assert result.empty\n",
    "        assert \"Dropped_Calls\" in result.columns\n",
    "        assert \"Handover_Failures\" in result.columns\n",
    "        assert \"Power_Outage\" in result.columns\n",
    "        assert \"Request_Failure_Rate\" in result.columns\n",
    "        assert \"failure_type\" in result.columns\n",
    "        assert result['failure_type'].dtype == object\n",
    "''')\n",
    "\n",
    "# Write the corrected test_failure_simulator.py content\n",
    "with open(\"/kaggle/working/test_failure_simulator.py\", \"w\") as f:\n",
    "    f.write(test_code)\n",
    "\n",
    "print(\"✅ test_failure_simulator.py and aei/telecom/failure/failure_simulator.py saved successfully.\")\n",
    "\n",
    "# Now, execute the pytest command\n",
    "print(\"\\nRunning pytest...\")\n",
    "!pytest /kaggle/working/test_failure_simulator.py -v"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7801414,
     "sourceId": 12372849,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.579571,
   "end_time": "2025-07-21T17:38:47.514318",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-21T17:38:38.934747",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
